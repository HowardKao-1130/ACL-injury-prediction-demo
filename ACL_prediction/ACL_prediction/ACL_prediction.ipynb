{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import ast\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "import datetime\n",
    "import glob\n",
    "import graphviz\n",
    "# from datetime import datetime\n",
    "from itertools import product\n",
    "from imblearn.metrics import specificity_score\n",
    "from itertools import combinations, chain\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_parallel_coordinate\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pydot\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import statistics\n",
    "from scipy.io import arff\n",
    "import sklearn\n",
    "import sklearn.utils\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    fbeta_score,\n",
    "    precision_score,\n",
    "    recall_score\n",
    ")\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, f1_score, precision_score, recall_score, fbeta_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from typing import Generator, Tuple, TypedDict, ClassVar, Union, List, Optional\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(sklearn.__version__)\n",
    "print(torch.__version__)\n",
    "print(xgb.__version__)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath(os.getcwd())\n",
    "notebook_name = os.path.basename(notebook_path)\n",
    "\n",
    "try:\n",
    "    file_idx = int(notebook_name.split('_')[-1])\n",
    "    print(f\"The integer at the end of the file name is: {file_idx}\")\n",
    "except ValueError:\n",
    "    try:\n",
    "        file_idx = int(notebook_name.split('_')[-2])\n",
    "        print(f\"The integer at the end of the file name is: {file_idx}\")\n",
    "    except ValueError:\n",
    "        print(\"The file name does not contain a valid integer at the end.\")\n",
    "\n",
    "combinations_1 = [[i] for i in range(1, 6)]\n",
    "combinations_2 = [list(c) for c in combinations(range(1, 6), 2)]\n",
    "combinations_3 = [list(c) for c in combinations(range(1, 6), 3)]\n",
    "combinations_4 = [list(c) for c in combinations(range(1, 6), 4)]\n",
    "combinations_5 = [[1, 2, 3, 4, 5]]\n",
    "\n",
    "all_combinations = sorted(combinations_1 + combinations_2 + combinations_3 + combinations_4 + combinations_5)\n",
    "# all_combinations = [[1, 2, 3, 4, 5]]\n",
    "# all_combinations = all_combinations[0:0]\n",
    "print(all_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predefined Dictionaries and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_rules_feature = {\n",
    "    \"M\": 1,\n",
    "    \"F\": 0,\n",
    "    \"yes\": 1,\n",
    "    \"no\":0\n",
    "}\n",
    "\n",
    "replacement_rules_label = {\n",
    "    \"yes\": 1,\n",
    "    \"no\": 0,\n",
    "    \"1\": 1,\n",
    "    \"2\": 0,\n",
    "    \"-1\": 0,\n",
    "    # \"Male\": -1,\n",
    "    \"Male\": 0,\n",
    "    \"Female\": 1\n",
    "}\n",
    "\n",
    "torch.serialization.add_safe_globals([nn.CrossEntropyLoss])\n",
    "loss_function_dict = {\n",
    "    # 'L1':  nn.L1Loss(),\n",
    "    # 'MSE': nn.MSELoss(),\n",
    "    'cross entropy': nn.CrossEntropyLoss()\n",
    "    # 'NLL': nn.NLLLoss(),\n",
    "    # 'CTC': nn.CTCLoss(),\n",
    "    # 'KL divergence': nn.KLDivLoss(),\n",
    "    # 'BCE logit': nn.BCEWithLogitsLoss()\n",
    "}\n",
    "\n",
    "index_val_count_dict = {\n",
    "    'index': 0, \n",
    "    'value': float('inf'), \n",
    "    'no_improvement_count': 0,\n",
    "    'model_to_save': None\n",
    "}\n",
    "\n",
    "class ModuleResults:\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        trained_models, \n",
    "        train_accuracy, \n",
    "        val_accuracy,\n",
    "        train_f1=None,\n",
    "        val_f1=None,\n",
    "        val_fb=None,\n",
    "        train_precision=None,\n",
    "        val_precision=None,\n",
    "        train_recall=None,\n",
    "        val_recall=None,\n",
    "        val_specificity=None,\n",
    "        train_auc=None,\n",
    "        val_auc=None,\n",
    "        stopping_epoch=None\n",
    "    ) -> None:\n",
    "\n",
    "        self.trained_models = trained_models\n",
    "        self.train_accuracy = train_accuracy\n",
    "        self.val_accuracy = val_accuracy\n",
    "        self.train_f1 = train_f1\n",
    "        self.val_f1 = val_f1\n",
    "        self.val_fb = val_fb\n",
    "        self.train_precision = train_precision\n",
    "        self.val_precision = val_precision\n",
    "        self.train_recall = train_recall\n",
    "        self.val_recall = val_recall\n",
    "        self.val_specificity = val_specificity\n",
    "        self.train_auc = train_auc\n",
    "        self.val_auc = val_auc\n",
    "        self.stopping_epoch=stopping_epoch\n",
    "\n",
    "class ValLossIndexAndValue(TypedDict):\n",
    "    index: int\n",
    "    value: float\n",
    "    no_improvement_count: int\n",
    "\n",
    "def create_dataframe(feature_combination_list, module_results_list):\n",
    "    data = [\n",
    "        {\n",
    "            \"Feature Combination\": feature_combination,\n",
    "            \"Accuracy\": metrics.accuracy_val,\n",
    "            \"F1 Score\": metrics.f1_val,\n",
    "            \"F-beta Score\": metrics.fb_val,\n",
    "            \"Precision\": metrics.precision_val,\n",
    "            \"Recall\": metrics.recall_val,\n",
    "            \"Specificity\": metrics.specificity_val,\n",
    "            \"Area Under Curve\": metrics.auc_val,\n",
    "            \"Stopping_Epoch\": metrics.stopping_epoch\n",
    "        }\n",
    "        for feature_combination, metrics in zip(feature_combination_list, module_results_list) \n",
    "    ]\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "class ModelConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type:str,\n",
    "        search_space:object,\n",
    "        name:str=None,\n",
    "        ensemble_group:str=None\n",
    "    ):\n",
    "        self.model_type = model_type       \n",
    "        self.search_space = search_space       \n",
    "        self.ensemble_group = ensemble_group     \n",
    "        self.name = name                   \n",
    "        self.model_instance = None            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_list_elements(list_to_combine:list[int]) -> str:\n",
    "    return ''.join(map(str, list_to_combine))\n",
    "\n",
    "def check_for_file_duplicates(directory:str, base_name:str, file_type:str) -> str:\n",
    "    \n",
    "    file_name = os.path.join(directory, base_name + \".\" + file_type)\n",
    "    \n",
    "    counter = 1\n",
    "    while os.path.exists(file_name):\n",
    "        file_name = os.path.join(directory, base_name + f\" ({counter}).{file_type}\")\n",
    "        counter += 1\n",
    "\n",
    "    return(file_name)\n",
    "\n",
    "def check_for_file_duplicates_short(path:str, file_type:str) -> str:\n",
    "    \n",
    "    counter = 1\n",
    "    file_name = path + f\"_{counter}{file_type}\"\n",
    "\n",
    "    while os.path.exists(file_name):\n",
    "        file_name = path + f\"_{counter}{file_type}\"\n",
    "        counter += 1\n",
    "\n",
    "    return(file_name)\n",
    "\n",
    "def check_for_file_duplicates_simple(path:str) -> str:\n",
    "\n",
    "    path = Path(path)\n",
    "\n",
    "    if not path.exists():\n",
    "        return str(path)\n",
    "\n",
    "    file_name = path.stem\n",
    "    file_extension = path.suffix\n",
    "    path_directory = path.parent\n",
    "\n",
    "    counter = 1\n",
    "    while True:\n",
    "        new_name = f\"{file_name}_{counter}{file_extension}\"\n",
    "        new_path = path_directory / new_name\n",
    "        \n",
    "        if not new_path.exists():\n",
    "            return str(new_path)\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "def custom_json_serializer(obj):\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "def sort_keys(key):\n",
    "    integers = [int(x) for x in re.findall(r'\\d+', str(key))]\n",
    "    return (len(integers), integers)\n",
    "\n",
    "def extract_integers(string):\n",
    "    # Use the re.findall() function to find all the integers in the string\n",
    "    integers = [int(x) for x in re.findall(r'\\d+', string)]\n",
    "    return integers\n",
    "\n",
    "def get_latest_base_folder(directory: str) -> str:\n",
    "    if not os.path.isdir(directory):\n",
    "        raise ValueError(f\"The directory '{directory}' does not exist or is not a directory.\")\n",
    "\n",
    "    entries = os.listdir(directory)\n",
    "    \n",
    "    base_folders = [\n",
    "        entry for entry in entries \n",
    "        if os.path.isdir(os.path.join(directory, entry)) and entry.startswith('base10000_')\n",
    "    ]\n",
    "    \n",
    "    if not base_folders:\n",
    "        raise ValueError(f\"No folders starting with 'base10000_' found in '{directory}'.\")\n",
    "        return None\n",
    "    \n",
    "    timestamp_pattern = r'base10000_(\\d{4})_(\\d{2})_(\\d{2})__(\\d{2})_(\\d{2})_(\\d{2})'\n",
    "    \n",
    "    latest_folder = None\n",
    "    latest_timestamp = None\n",
    "    \n",
    "    for folder in base_folders:\n",
    "        match = re.match(timestamp_pattern, folder)\n",
    "        if match:\n",
    "            year, month, day, hour, minute, second = map(int, match.groups())\n",
    "            \n",
    "            try:\n",
    "                folder_timestamp = datetime.datetime(year, month, day, hour, minute, second)\n",
    "            except ValueError as e:\n",
    "                print(f\"Invalid timestamp in folder '{folder}': {e}\")\n",
    "                continue\n",
    "            \n",
    "            if latest_timestamp is None or folder_timestamp > latest_timestamp:\n",
    "                latest_timestamp = folder_timestamp\n",
    "                latest_folder = folder\n",
    "        else:\n",
    "            print(f\"Folder '{folder}' does not match the expected timestamp format.\")\n",
    "    \n",
    "    if latest_folder is None:\n",
    "        print(\"No folders with valid timestamps found.\")\n",
    "        return None\n",
    "    \n",
    "    return os.path.join(directory, latest_folder)\n",
    "\n",
    "def tensor_2_np(loader):\n",
    "    X, y = [], []\n",
    "    for i in range(len(loader.dataset)):\n",
    "        x, target = loader.dataset[i]\n",
    "        X.append(x)\n",
    "        y.append(target)\n",
    "    return torch.stack(X).numpy(), torch.stack(y).numpy()\n",
    "\n",
    "def numpy_2_dataloader(X: np.ndarray, Y: np.ndarray, batch_size: int) -> tuple[DataLoader, DataLoader]:\n",
    "\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    Y_tensor = torch.tensor(Y, dtype=torch.long, device=device)\n",
    "\n",
    "    dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "def majority_vote(predictions: List[np.ndarray]) -> np.ndarray:\n",
    "    pred_array = np.vstack(predictions)\n",
    "    votes_for_1 = np.sum(pred_array, axis=0)\n",
    "    n_models = len(predictions)\n",
    "    return (votes_for_1 > n_models / 2).astype(int)\n",
    "\n",
    "def check_tune_consistency(tuned_performance, actual_performance):\n",
    "    \n",
    "    print('\\n')\n",
    "    print(f'Tuned: {tuned_performance}')\n",
    "    print(f'Actual: {actual_performance}')\n",
    "    print('\\n')\n",
    "    if tuned_performance == actual_performance:\n",
    "        print(f'Successful tuning!')\n",
    "    else: \n",
    "        print(f'Failed tuning!')\n",
    "\n",
    "def string_to_list(s):\n",
    "    try:\n",
    "        # Parse string to list\n",
    "        result = ast.literal_eval(s)\n",
    "        # Ensure all elements are integers\n",
    "        if isinstance(result, list):\n",
    "            return [int(x) for x in result]\n",
    "        else:\n",
    "            raise ValueError(\"Input is not a list\")\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing string {s}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Modality class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modality:\n",
    "\n",
    "    def __init__(self, \n",
    "                mode:str,\n",
    "                model_choice:str, \n",
    "                metric:str,\n",
    "                is_developer_test_mode:bool, \n",
    "                uses_K_Fold:bool, \n",
    "                uses_existing_model:bool, \n",
    "                saves_plot:bool,\n",
    "                is_verbose:bool,\n",
    "                standardizes_input:bool,\n",
    "                uses_early_stopping:bool,\n",
    "                bagging_strategy:str,\n",
    "                random_state:int) -> None:\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.model_choice = model_choice\n",
    "        self.metric = metric\n",
    "        self.is_developer_test_mode = is_developer_test_mode\n",
    "        self.uses_K_Fold = uses_K_Fold\n",
    "        self.uses_existing_model = uses_existing_model\n",
    "        self.saves_plot = saves_plot\n",
    "        self.is_verbose = is_verbose\n",
    "        self.standardizes_input = standardizes_input\n",
    "        self.uses_early_stopping = uses_early_stopping\n",
    "        self.bagging_strategy = bagging_strategy\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"Modality =============================:\"]        \n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def __init__(self, \n",
    "                raw_dataset_name:str, \n",
    "                train_ratio:float, \n",
    "                n_classes:int,\n",
    "                columns_to_keep:list[int],\n",
    "                data_split_random_seed_modfier:int) -> None:\n",
    "        \n",
    "        self.raw_dataset_name = raw_dataset_name\n",
    "        self.dataset_name = None\n",
    "        self.batch_sizes:list[int] = None\n",
    "        \n",
    "        self.columns_to_keep = columns_to_keep\n",
    "        self.data_split_random_seed_modfier = data_split_random_seed_modfier\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.train_ratio = train_ratio\n",
    "        self.validation_ratio:float = 1 - self.train_ratio\n",
    "        self.k_folds:int = int(1 / self.validation_ratio)\n",
    "        \n",
    "        self.df:pd.DataFrame = None\n",
    "        \n",
    "        self.columns_all:list[int] = None\n",
    "        self.columns_remaining:list[int] = None\n",
    "        self.columns_remaining_str:str = None\n",
    "\n",
    "        self.X:torch.Tensor = None\n",
    "        self.Y:torch.Tensor = None\n",
    "\n",
    "        self.X_train_val:torch.Tensor = None\n",
    "        self.Y_train_val:torch.Tensor = None\n",
    "\n",
    "        self.X_train:torch.Tensor = None\n",
    "        self.Y_train:torch.Tensor = None\n",
    "\n",
    "        self.X_val:torch.Tensor = None\n",
    "        self.Y_val:torch.Tensor = None\n",
    "        \n",
    "        self.X_test:torch.Tensor = None\n",
    "        self.Y_test:torch.Tensor = None\n",
    "\n",
    "        self.train_val_loader:torch.Tensor = None\n",
    "        self.test_loader:torch.Tensor = None\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"Dataset =============================:\"]        \n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define searcg space classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MLP_SearchSpace:\n",
    "    max_epoch_range: int\n",
    "    batch_size_range: List[int]\n",
    "    model_depth_range: List[int]\n",
    "    model_width_range: List[int]\n",
    "    model_lr_range: List[float]\n",
    "    model_dr_range: List[float]\n",
    "    activation_function_range: List[str]\n",
    "    weight_decay_range: List[float]\n",
    "    criterion_range: List[str]\n",
    "    num_optuna_trials: int\n",
    "    # warm_up_range: int\n",
    "    patience_range: int\n",
    "    # moving_average_range: int\n",
    "    l1_weight_range: List[float]\n",
    "    l2_weight_range: List[float]\n",
    "    num_optuna_trials:int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "    optuna_step_for_model_depth:int = 1\n",
    "    optuna_step_for_model_width:int = 1\n",
    "    optuna_step_for_lr:float = None\n",
    "    optuna_step_for_dr:float = None\n",
    "    optuna_step_for_weight_decay:float = None\n",
    "    optuna_step_for_warm_up:int = 5\n",
    "    optuna_step_for_patience:int = 5\n",
    "    optuna_step_for_moving_average:int = 5\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"MLP Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "@dataclass\n",
    "class TAB_SearchSpace: \n",
    "    batch_size_range: List[int]\n",
    "    width_prediction_and_attention_range: List[int]\n",
    "    n_step_range: List[int]\n",
    "    gamma_range: List[float]\n",
    "    cat_idx_range: List[int]\n",
    "    cat_dim_range: List[int]\n",
    "    n_independent_range: List[int]\n",
    "    n_shared_range: List[int]\n",
    "    momentum_range: List[float]\n",
    "    lambda_sparse_range: List[float]\n",
    "    mask_type_range: List[str]\n",
    "    # optimizer_param_range: List[float]\n",
    "    # max_epoch_range: List[int]\n",
    "    # patience_range: List[int]\n",
    "    # max_epoch_range: List[int]\n",
    "    num_optuna_trials:int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"TAB Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "@dataclass\n",
    "class SVM_SearchSpace:\n",
    "    batch_size_range: List[int]\n",
    "    c_range: List[float]\n",
    "    kernel_range: List[str]\n",
    "    gamma_range: List[float]\n",
    "    tol_range: List[float]\n",
    "    max_iter_range: List[int]\n",
    "    degree_range: List[int]\n",
    "    num_optuna_trials: int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"SVM Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "@dataclass\n",
    "class KNN_SearchSpace:\n",
    "    batch_size_range: List[int]\n",
    "    n_neighbor_range: List[int]\n",
    "    weight_range: List[str]\n",
    "    algorithm_range: List[str]\n",
    "    leaf_size_range: List[int]\n",
    "    p_range: List[float]\n",
    "    metric_range: List[str]\n",
    "    num_optuna_trials: int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "    optuna_step_for_n_neighbor:int = 1\n",
    "    optuna_step_for_leaf_size:int = 1\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"KNN Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RF_SearchSpace:\n",
    "    batch_size_range: List[int]\n",
    "    num_tree_range: List[int]\n",
    "    criterion_range: List[str]\n",
    "    max_depth_range: List[Optional[int]]\n",
    "    min_sample_split_range: List[Union[int, float]]\n",
    "    min_sample_leaf_range: List[int]\n",
    "    max_feature_range: List[Optional[str]]\n",
    "    max_leaf_node_range: List[Optional[int]]\n",
    "    bootstrap_range: List[bool]\n",
    "    min_impurity_decrease_range: List[float]\n",
    "    ccp_alpha_range: List[float]\n",
    "    max_sample_range: List[float]\n",
    "    num_optuna_trials: int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "    optuna_step_for_num_tree:int = 1\n",
    "    optuna_step_for_max_depth:int = 1\n",
    "    optuna_step_for_max_leaf_node:int = 1\n",
    "    optuna_step_for_min_sample_split:float = None\n",
    "    optuna_step_for_min_smaple_leaf:float = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"RF Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class XGB_SearchSpace:\n",
    "    batch_size_range: List[int]\n",
    "    eta_range: List[float]\n",
    "    gamma_range: List[float]\n",
    "    max_depth_range: List[int]\n",
    "    min_child_weight_range: List[float]\n",
    "    subsample_range: List[float]\n",
    "    sampling_method_range: List[str]\n",
    "    reg_lambda_range: List[float]\n",
    "    reg_alpha_range: List[float]\n",
    "    early_stopping_rounds_range: List[int]\n",
    "    grow_policy_range: List[str]\n",
    "    max_leaf_range: List[int]\n",
    "    num_optuna_trials: int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "    optuna_step_for_max_depth:int = 1\n",
    "    optuna_step_for_max_leaf:int = 1\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"XGB Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CAT_SearchSpace:\n",
    "    batch_size_range: List[int]\n",
    "    cat_features_range: List[int]\n",
    "    early_stopping_rounds_range: List[int]\n",
    "    learning_rate_range: List[float]\n",
    "    depth_range: List[int]\n",
    "    l2_leaf_reg_range: List[float]\n",
    "    random_strength_range: List[float]\n",
    "    colsample_range: List[float]\n",
    "    bagging_temperature_range: List[float]\n",
    "    border_count_range: List[int]\n",
    "    num_optuna_trials: int\n",
    "\n",
    "    optuna_step_for_batch_size:int = 32\n",
    "    optuna_step_for_iteration:int = 5\n",
    "    optuna_step_for_depth:int = 1\n",
    "    optuna_step_for_early_stopping_round:int = 1\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"CAT Search Space =============================:\"]\n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define trial information class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrialInformation:\n",
    "\n",
    "    def __init__(self, time_stamp:str, trial_name:str):\n",
    "\n",
    "        self.time_stamp:str = time_stamp\n",
    "        self.trial_name:str = trial_name\n",
    "\n",
    "        self.model_save_path:str = None\n",
    "        self.hyperparam_save_path:str = None\n",
    "        self.summary_save_path:str = None\n",
    "        self.candidate_list_save_path:str = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        lines = [\"Trial Information =============================:\"]        \n",
    "        for name, value in vars(self).items():\n",
    "            lines.append(f\"       - {name}: {value}\")\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMlpModel(nn.Module):\n",
    "    \n",
    "    activation_function_dict = {\n",
    "        'relu': nn.ReLU(),\n",
    "        'tanh': nn.Tanh(),\n",
    "        'elu': nn.ELU(),\n",
    "        'leaky relu': nn.LeakyReLU(),\n",
    "        'log sigmoid': nn.LogSigmoid(),\n",
    "        'continuous relu': nn.CELU(),\n",
    "        'relu 6': nn.ReLU6(),\n",
    "        'gaussian relu': nn.GELU(),\n",
    "        'sigmoid': nn.Sigmoid(),\n",
    "        'sigmoid relu': nn.SiLU()\n",
    "    }\n",
    "    \n",
    "    def __init__(self, \n",
    "                max_epoch:int,\n",
    "                batch_size: int,\n",
    "                device:torch.device, \n",
    "                input_dim:int, \n",
    "                n_classes:int, \n",
    "                model_depth:int, \n",
    "                model_width:int,\n",
    "                criterion, \n",
    "                model_dr:float,\n",
    "                model_lr:float, \n",
    "                l1_weight:float,\n",
    "                l2_weight:float,\n",
    "                weight_decay:float,\n",
    "                activation_function:str,\n",
    "                # warm_up:int,\n",
    "                patience:int,\n",
    "                # moving_average:int,\n",
    "                random_state:int,\n",
    "                feature_combination_str: str = None):\n",
    "        \n",
    "        super(myMlpModel, self).__init__()\n",
    "\n",
    "        torch.manual_seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        random.seed(random_state)\n",
    "\n",
    "        for name, value in locals().items():\n",
    "            if name != 'self': \n",
    "                setattr(self, name, value)\n",
    "\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        self.batchnorm_layers = nn.ModuleList()\n",
    "        self.dropout_layers = nn.ModuleList()\n",
    "        self.activation_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(model_depth):\n",
    "            self.fc_layers.append(nn.Linear(input_dim if i == 0 else model_width, model_width, dtype=torch.float32).to(self.device))\n",
    "            self.batchnorm_layers.append(nn.BatchNorm1d(model_width).to(self.device))\n",
    "            self.dropout_layers.append(nn.Dropout(model_dr).to(self.device))\n",
    "            self.activation_layers.append(self.activation_function_dict[activation_function].to(self.device))\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=model_lr, weight_decay=weight_decay)\n",
    "\n",
    "        self.fc_last = nn.Linear(model_width, n_classes, dtype=torch.float32).to(self.device)\n",
    "        self.softmax = nn.Softmax(dim=1).to(self.device)\n",
    "        \n",
    "    def forward(self, x_initial:torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = x_initial.to(self.device).float()\n",
    "        for i in range(self.model_depth):\n",
    "            residual = x\n",
    "\n",
    "            x = self.activation_layers[i](self.fc_layers[i](x))\n",
    "\n",
    "            if self.training:\n",
    "                x = self.dropout_layers[i](x)\n",
    "    \n",
    "            if (i != 0):\n",
    "                x = residual + x\n",
    "            x = self.batchnorm_layers[i](x)\n",
    "\n",
    "        x = self.fc_last(x)\n",
    "        x_soft = self.softmax(x)\n",
    "        return x_soft\n",
    "    \n",
    "\n",
    "    def calculate_l1_loss(self):\n",
    "        l1 = 0.0\n",
    "        for param in self.parameters():\n",
    "            l1 += torch.sum(torch.abs(param))\n",
    "        return self.l1_weight * l1\n",
    "\n",
    "    def calculate_l2_loss(self):\n",
    "        l2 = 0.0\n",
    "        for param in self.parameters():\n",
    "            l2 += torch.sum(param ** 2)\n",
    "        return self.l2_weight * l2\n",
    "\n",
    "    def predict(self, loader, _=None):\n",
    "        self.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for features, _ in loader:\n",
    "                features = features.to(device, dtype=torch.float32)\n",
    "                outputs = self(features)  \n",
    "                predicted_class = torch.argmax(outputs, dim=1)\n",
    "                predictions.append(predicted_class.cpu())\n",
    "        return torch.cat(predictions).numpy()  \n",
    "\n",
    "    def predict_proba(self, loader, _=None):\n",
    "        self.eval()\n",
    "        probas = []\n",
    "        with torch.no_grad():\n",
    "            for features, _ in loader:\n",
    "                features = features.to(device, dtype=torch.float32)\n",
    "                outputs = self(features)  \n",
    "                probas.append(outputs.cpu())\n",
    "        return torch.cat(probas).numpy()  \n",
    "\n",
    "    def score(self, loader, _=None):\n",
    "        \n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, targets in loader:\n",
    "                features = features.to(device, dtype=torch.float32)\n",
    "                targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "                softmax = self(features)\n",
    "\n",
    "                predicted_class = torch.max(softmax, 1).indices\n",
    "                correct += (predicted_class == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def predict_and_score(self, loader):\n",
    "        \n",
    "        self.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for features, targets in loader:\n",
    "                features = features.to(device, dtype=torch.float32)\n",
    "                targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "                softmax = self(features)\n",
    "                loss_nominal = self.criterion(softmax, targets)  \n",
    "                \n",
    "                l1_loss = self.calculate_l1_loss()\n",
    "                l2_loss = self.calculate_l2_loss()\n",
    "\n",
    "                total_loss += loss_nominal.item()\n",
    "\n",
    "                predicted_class = torch.max(softmax, 1).indices\n",
    "                correct += (predicted_class == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        avg_loss = total_loss / len(loader)\n",
    "\n",
    "        return accuracy, avg_loss\n",
    "\n",
    "    def train_epoch(self, train_loader, val_loader=None):\n",
    "        \n",
    "        self.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        total_loss_nominal = 0\n",
    "\n",
    "        for batch_idx, (features, targets) in enumerate(train_loader) :\n",
    "\n",
    "            self.zero_grad()\n",
    "            self.optimizer.zero_grad()\n",
    "            features, targets = features.to(device, dtype=torch.float32), targets.to(device, dtype=torch.long)\n",
    "            \n",
    "            softmax = self(features)\n",
    "            loss_nominal = self.criterion(softmax, targets)\n",
    "\n",
    "            l1_loss = self.calculate_l1_loss()\n",
    "            l2_loss = self.calculate_l2_loss()\n",
    "\n",
    "            batch_loss = loss_nominal + l1_loss + l2_loss\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += batch_loss.item()\n",
    "            total_loss_nominal += loss_nominal.item()\n",
    "            \n",
    "            predicted_class = torch.max(softmax, 1).indices\n",
    "            correct += (predicted_class == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "        \n",
    "        train_accuracy = correct / total\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_loss_nominal = total_loss_nominal / len(train_loader)\n",
    "\n",
    "        val_accuracy, val_loss = None, None\n",
    "        if val_loader is not None:\n",
    "            val_accuracy, val_loss = self.predict_and_score(val_loader)\n",
    "\n",
    "        return train_accuracy, val_accuracy, val_loss\n",
    "    \n",
    "    def fit(self, train_loader, val_loader=None):\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(self.max_epoch):\n",
    "            train_accuracy, val_accuracy, val_loss = self.train_epoch(train_loader, val_loader)\n",
    "            if val_loader is not None: \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_model_state = self.state_dict()  \n",
    "                    best_epoch = epoch + 1\n",
    "                    patience_counter = 0 \n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= self.patience:\n",
    "                        break\n",
    "            else:\n",
    "                best_model_state = self.state_dict()\n",
    "                best_epoch = epoch + 1\n",
    "        \n",
    "        self.load_state_dict(best_model_state)\n",
    "        self.best_iteration = best_epoch\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_AUC_and_ROC(model:nn.Module, validate_dataloader:DataLoader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_pred = []\n",
    "        Y_true = []\n",
    "        for batch_idx, (features, targets) in enumerate(validate_dataloader) :\n",
    "            features, targets = features.to(device, dtype=torch.float32), targets.to(device, dtype=torch.long)\n",
    "            softmax = model(features)\n",
    "            Y_pred.extend(softmax.detach().cpu().numpy()[:, 1])\n",
    "            Y_true.extend(targets.detach().cpu().numpy())\n",
    "            predicted_class = torch.max(softmax, 1).indices\n",
    "            fpr, tpr, thresholds = roc_curve(Y_true, Y_pred) \n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.4f)' % roc_auc)\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining pipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        self.modality:Modality = None\n",
    "        self.data:Data = None\n",
    "        self.model_configs: list[ModelConfig] = []\n",
    "        self._registry = {\n",
    "            \"MLP\": MLP_SearchSpace,\n",
    "            \"TAB\": TAB_SearchSpace,\n",
    "            \"SVM\": SVM_SearchSpace,\n",
    "            \"RF\": RF_SearchSpace,\n",
    "            \"KNN\": KNN_SearchSpace,\n",
    "            \"XGB\": XGB_SearchSpace,\n",
    "            \"CAT\": CAT_SearchSpace\n",
    "        }\n",
    "        self.trial_info:TrialInformation = None\n",
    "        self.n_base_models:list[int] = None\n",
    "\n",
    "    def add_model_config(self, model_type:str, ensemble_group:str=None, name:str=None, **kwargs) -> None:\n",
    "        if model_type not in self._registry:\n",
    "            raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "        SearchSpaceClass = self._registry[model_type]\n",
    "        search_space = SearchSpaceClass(**kwargs)\n",
    "\n",
    "        config = ModelConfig(\n",
    "            model_type=model_type,\n",
    "            search_space=search_space,\n",
    "            ensemble_group=ensemble_group,\n",
    "            name=name\n",
    "        )\n",
    "        self.model_configs.append(config)\n",
    "\n",
    "    def get_configs_by_group(self, group_name:str) -> list[ModelConfig]:\n",
    "        return [config for config in self.model_configs if config.ensemble_group == group_name]\n",
    "\n",
    "    def list_models(self) -> None:\n",
    "        for cfg in self.model_configs:\n",
    "            print(f\"Model: {cfg.name}, Type: {cfg.model_type}, Group: {cfg.ensemble_group}\")\n",
    "\n",
    "    def set_n_base_model_range(self, range:list[int]) -> None:\n",
    "        self.n_base_models = range\n",
    "\n",
    "    def set_Modality(self, \n",
    "        mode:str, \n",
    "        model_choice:str,\n",
    "        metric:str,\n",
    "        is_developer_test_mode:bool=False, \n",
    "        uses_K_Fold:bool=True, \n",
    "        uses_existing_model:bool=False, \n",
    "        saves_plot:bool=False,\n",
    "        is_verbose:bool=False,\n",
    "        standardizes_input:bool=True,\n",
    "        uses_early_stopping:bool=True,\n",
    "        bagging_strategy:str='None',\n",
    "        random_state:int=42) -> None:\n",
    "        \n",
    "        self.modality = Modality(\n",
    "            mode=mode, \n",
    "            model_choice=model_choice,\n",
    "            metric=metric,\n",
    "            is_developer_test_mode=is_developer_test_mode, \n",
    "            uses_K_Fold=uses_K_Fold, \n",
    "            uses_existing_model=uses_existing_model, \n",
    "            saves_plot=saves_plot, \n",
    "            is_verbose=is_verbose,\n",
    "            standardizes_input=standardizes_input,\n",
    "            uses_early_stopping=uses_early_stopping,\n",
    "            bagging_strategy=bagging_strategy,\n",
    "            random_state=random_state)\n",
    "\n",
    "    def set_Data(self, \n",
    "        raw_dataset_name:str='tibial_slope', \n",
    "        train_ratio:float=0.9, \n",
    "        n_classes:int=2, \n",
    "        columns_to_keep:list[int]=[], \n",
    "        data_split_random_seed_modfier:int=0) -> None:\n",
    "        \n",
    "        self.data = Data(\n",
    "            raw_dataset_name=raw_dataset_name, \n",
    "            train_ratio=train_ratio, \n",
    "            n_classes=n_classes, \n",
    "            columns_to_keep=columns_to_keep,\n",
    "            data_split_random_seed_modfier=data_split_random_seed_modfier)\n",
    "\n",
    "    def set_TrialInformation(self) -> None:\n",
    "        \n",
    "        timestamp = datetime.datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "        trial_name = f\"{self.modality.model_choice}_{self.modality.metric}_{self.data.columns_remaining}\"\n",
    "        self.trial_info = TrialInformation(timestamp, trial_name)\n",
    "\n",
    "        current_dir = os.getcwd()\n",
    "        trial_base_name = f'{self.trial_info.trial_name}'\n",
    "\n",
    "        if self.modality.bagging_strategy == 'None':\n",
    "            trial_sub_folder_upper = f'{self.modality.model_choice}'\n",
    "        elif self.modality.bagging_strategy == 'single':\n",
    "            trial_sub_folder_upper = f'{self.modality.model_choice}_ensemble'\n",
    "        elif self.modality.bagging_strategy == 'diverse': \n",
    "            trial_sub_folder_upper = f'ensemble_diverse'\n",
    "\n",
    "        trial_sub_folder = f'{trial_sub_folder_upper}/{self.data.columns_remaining}/{self.modality.metric}/seed_{self.modality.random_state+self.data.data_split_random_seed_modfier}/{self.trial_info.time_stamp}'\n",
    "\n",
    "        summary_save_directory = f'../Model Evaluation/{self.data.raw_dataset_name}/{trial_sub_folder}'\n",
    "        os.makedirs(summary_save_directory, exist_ok=True) if self.modality.mode == 'train' else None\n",
    "        model_save_path = os.path.join(summary_save_directory, f'{trial_base_name}.pth')\n",
    "\n",
    "        hyperparam_save_directory = f'../Hyperparameter tuning/Optuna/{self.data.raw_dataset_name}/{trial_sub_folder}'\n",
    "        os.makedirs(hyperparam_save_directory, exist_ok=True) if self.modality.mode == 'optuna' else None\n",
    "        hyperparam_save_path = os.path.join(hyperparam_save_directory, f'{trial_base_name}.txt')\n",
    "\n",
    "        summary_save_directory = f'../Model Evaluation/Test Performance Summary/{self.data.raw_dataset_name}/{self.modality.metric}/seed_{self.modality.random_state+self.data.data_split_random_seed_modfier}'\n",
    "        os.makedirs(summary_save_directory, exist_ok=True) if self.modality.mode == 'eval' else None\n",
    "        summary_save_path = os.path.join(summary_save_directory, f'metric_summary_{self.modality.metric}_{self.data.raw_dataset_name}.csv')\n",
    "        candidate_list_save_path = os.path.join(summary_save_directory, f'candidate_list_{self.modality.metric}_{self.data.raw_dataset_name}.csv')\n",
    "\n",
    "        self.trial_info.model_save_path = model_save_path\n",
    "        self.trial_info.hyperparam_save_path = hyperparam_save_path\n",
    "        self.trial_info.summary_save_path = summary_save_path\n",
    "        self.trial_info.candidate_list_save_path = candidate_list_save_path\n",
    "\n",
    "    def load_dataset(self) -> None:\n",
    "\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "        dataset_dir = os.path.join(os.path.dirname(current_dir), \"Datasets\")\n",
    "        os.chdir(dataset_dir)\n",
    "\n",
    "        files = [f for f in os.listdir('.') if f.startswith(self.data.raw_dataset_name)]\n",
    "        if not files:\n",
    "            raise ValueError(f\"No files found in the current directory starting with '{self.data.raw_dataset_name}'.\")\n",
    "        \n",
    "        file = files[0]\n",
    "        self.data.dataset_name = file\n",
    "        try:\n",
    "            if file.endswith('.csv'):\n",
    "                self.data.df = pd.read_csv(file, header=0)\n",
    "            elif file.endswith('.arff'):\n",
    "                with open(file, 'r') as f:\n",
    "                    data, meta = arff.loadarff(f)\n",
    "                    data_list = [dict(zip(meta.names(), row)) for row in data]\n",
    "                    for row in data_list:\n",
    "                        for col, value in row.items():\n",
    "                            if isinstance(value, bytes):\n",
    "                                row[col] = value.decode('utf-8')\n",
    "                    self.data.df = pd.DataFrame(data_list)\n",
    "            else:\n",
    "                with open(file, 'r') as f:\n",
    "                    data, meta = arff.loadarff(f)\n",
    "                    data_list = [dict(zip(meta.names(), row)) for row in data]\n",
    "                    for row in data_list:\n",
    "                        for col, value in row.items():\n",
    "                            if isinstance(value, bytes):\n",
    "                                row[col] = value.decode('utf-8')\n",
    "                    self.data.df = pd.DataFrame(data_list)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Unable to load the dataset file: {e}\")\n",
    "        \n",
    "        if self.modality.is_verbose:\n",
    "            corr_matrix = pd.DataFrame(self.data.df[self.data.df.columns.tolist()[1 :]], columns=self.data.df.columns.tolist()[1 :]).corr()\n",
    "            sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=True, fmt='.2f')\n",
    "            plt.show()\n",
    "\n",
    "        self.data.columns_all = list(range(1, len(self.data.df.columns) - 1))\n",
    "        os.chdir(current_dir)\n",
    "\n",
    "    def modify_dataset(self) -> None:\n",
    "\n",
    "        columns_to_discard = list(set(self.data.columns_all) - set(self.data.columns_to_keep))\n",
    "        self.data.columns_remaining = list(set(self.data.columns_all) - set(columns_to_discard))\n",
    "        self.data.columns_remaining_str = combine_list_elements(self.data.columns_remaining)\n",
    "\n",
    "    def split_dataset(self) -> None:\n",
    "\n",
    "        # the replace() invoked triggers an additional datatype evaluation and does not do anything else\n",
    "        self.data.X = self.data.df.iloc[:, 0:-1].iloc[:, self.data.columns_remaining].replace(replacement_rules_feature).astype(float).values \n",
    "        self.data.Y = self.data.df.iloc[:, -1].replace(replacement_rules_label).values\n",
    "        self.data.X_train_val, self.data.X_test, self.data.Y_train_val, self.data.Y_test = train_test_split(self.data.X, self.data.Y, test_size=0.15, random_state=self.modality.random_state+self.data.data_split_random_seed_modfier, stratify=self.data.Y, shuffle=True)\n",
    "        \n",
    "    def kfold_loaders(self, model_type: str = None) -> Generator[tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray], None, None]:\n",
    "\n",
    "        def replace_func(X):\n",
    "\n",
    "            vectorized_replace = np.vectorize(lambda x: replacement_rules_feature.get(x, 0))\n",
    "            return vectorized_replace(X).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "        def standardize(X_train, X_other):\n",
    "            \n",
    "            X_train_main, X_train_last = X_train[:, :-1], X_train[:, -1:]\n",
    "            X_other_main, X_other_last = X_other[:, :-1], X_other[:, -1:]\n",
    "\n",
    "            if model_type not in ['CAT', 'TAB', 'TABold']:\n",
    "\n",
    "                X_train_main = np.hstack((X_train_main, X_train_last))\n",
    "                X_other_main = np.hstack((X_other_main, X_other_last))\n",
    "\n",
    "            means = np.mean(X_train_main, axis=0)\n",
    "            stds = np.std(X_train_main, axis=0)\n",
    "\n",
    "            X_train_standardized_portion = (X_train_main - means) / stds\n",
    "            X_other_standardized_portion = (X_other_main - means) / stds\n",
    "\n",
    "            if model_type in ['CAT', 'TAB', 'TABold']:\n",
    "\n",
    "                X_train = np.hstack((X_train_standardized_portion, X_train_last))\n",
    "                X_other = np.hstack((X_other_standardized_portion, X_other_last))\n",
    "\n",
    "            else:\n",
    "\n",
    "                X_train = X_train_standardized_portion\n",
    "                X_other = X_other_standardized_portion\n",
    "\n",
    "            return X_train, X_other\n",
    "        \n",
    "        if self.modality.mode in ['train', 'eval', 'feature', 'deploy']:\n",
    "            X_train = self.data.X_train_val\n",
    "            X_test = self.data.X_test\n",
    "            Y_train = self.data.Y_train_val\n",
    "            Y_test = self.data.Y_test\n",
    "\n",
    "            if self.modality.mode in ['train', 'eval', 'feature']:\n",
    "                X_train, X_test = standardize(X_train, X_test)\n",
    "                yield X_train, Y_train, X_test, Y_test\n",
    "            elif self.modality.mode in ['deploy']:\n",
    "                X_full = np.concatenate((X_train, X_val), dim=0)\n",
    "                Y_full = np.concatenate((Y_train, Y_val), dim=0)\n",
    "                yield None, None, X_full, Y_full \n",
    "\n",
    "        else:\n",
    "            X = self.data.X_train_val\n",
    "            Y = self.data.Y_train_val\n",
    "            skf = StratifiedKFold(n_splits=self.data.k_folds, shuffle=True, random_state=self.modality.random_state)\n",
    "\n",
    "            for train_index, test_index in skf.split(X, Y):\n",
    "                X_train = X[train_index]\n",
    "                X_val = X[test_index]\n",
    "                Y_train = Y[train_index]\n",
    "                Y_val = Y[test_index]\n",
    "\n",
    "                X_train, X_val = standardize(X_train, X_val)\n",
    "\n",
    "                yield X_train, Y_train, X_val, Y_val\n",
    "            \n",
    "    def fit_and_compute_metrics(self, models, model_type, X_train, Y_train, X_val, Y_val, metrics, **kwargs):\n",
    "\n",
    "        Y_pred_train = []\n",
    "        Y_pred_val = []\n",
    "        Y_pred_val_proba = []\n",
    "        Y_pred_train_proba = []\n",
    "\n",
    "        val_loader = numpy_2_dataloader(X=X_val,  Y=Y_val, batch_size=128)\n",
    "\n",
    "        for base_model_idx, base_model in enumerate(models):\n",
    "            \n",
    "            if self.modality.bagging_strategy == 'None':\n",
    "                X_train_bagged, Y_train_bagged = (X_train, Y_train)\n",
    "            elif self.modality.bagging_strategy == 'single':\n",
    "                X_train_bagged, Y_train_bagged = sklearn.utils.resample(X_train, Y_train, replace=True, n_samples=len(X_train), random_state=self.modality.random_state+base_model_idx)\n",
    "\n",
    "            # print(f'X_train_bagged: {X_train_bagged}')\n",
    "            train_loader = numpy_2_dataloader(X=X_train_bagged,  Y=Y_train_bagged, batch_size=128)\n",
    "\n",
    "            if model_type == 'MLP':\n",
    "                # print(train_loader[0].shape)\n",
    "                X_train_bagged = train_loader\n",
    "                X_val = val_loader\n",
    "                val_loader_early_stopping = val_loader\n",
    "\n",
    "            if model_type in ['TAB', 'TABold']:\n",
    "                patience = 25 if self.modality.mode in ['optuna', 'check'] else 0\n",
    "                eval_set = [(X_train, Y_train), (X_val, Y_val)]\n",
    "                # print(f'train:\\n{X_train[0:5,:]}\\n\\n val:\\n{X_val[0:5,:]}')\n",
    "                eval_name = ['train', 'test']\n",
    "\n",
    "            if model_type == 'CAT':\n",
    "\n",
    "                cat_features = [self.data.columns_remaining.index(5)] if '5' in self.data.columns_remaining_str else []\n",
    "\n",
    "                if cat_features:  # If there are categorical features\n",
    "                    cat_idx = cat_features[0]  # Index of the categorical column (e.g., '5')\n",
    "                    # Ensure categorical column is str for CatBoost\n",
    "                    X_train_bagged = X_train_bagged.copy().astype(object)  # Avoid modifying original array\n",
    "                    X_val = X_val.copy().astype(object)\n",
    "                    X_train_bagged[:, cat_idx] = X_train_bagged[:, cat_idx].astype(np.int64)\n",
    "                    X_val[:, cat_idx] = X_val[:, cat_idx].astype(np.int64)\n",
    "        \n",
    "                train_pool = Pool(X_train_bagged, Y_train_bagged, cat_features=cat_features)\n",
    "                val_pool = Pool(X_val, Y_val, cat_features=cat_features)\n",
    "            \n",
    "            if model_type == 'XGB':\n",
    "                eval_set = [(X_val, Y_val)]\n",
    "\n",
    "            if self.modality.mode == 'train':\n",
    "                val_loader_early_stopping = None\n",
    "                val_pool = None\n",
    "                eval_set = None\n",
    "                eval_name = None\n",
    "\n",
    "            if self.modality.mode not in ['eval', 'deploy', 'eval_val']:\n",
    "                if model_type in ['MLP']:\n",
    "                    base_model.fit(train_loader, val_loader_early_stopping)\n",
    "                elif model_type in ['TAB', 'TABold']:\n",
    "                    base_model.fit(X_train=X_train, \n",
    "                                y_train=Y_train, \n",
    "                                eval_set=eval_set, \n",
    "                                eval_name=eval_name, \n",
    "                                eval_metric=['accuracy', 'logloss'], \n",
    "                                max_epochs=kwargs.get('max_epoch', 200), \n",
    "                                patience=patience, \n",
    "                                batch_size=X_train.shape[0]) \n",
    "                elif model_type in ['XGB']:\n",
    "                    base_model.fit(X_train_bagged, Y_train_bagged, eval_set=eval_set, verbose=False)\n",
    "                elif model_type in ['CAT']:\n",
    "                    base_model.fit(train_pool, eval_set=val_pool)\n",
    "                elif model_type in ['SVM', 'RF', 'KNN']:\n",
    "                    base_model.fit(X_train_bagged, Y_train_bagged)\n",
    "\n",
    "            Y_pred_train.append(base_model.predict(X_train_bagged))\n",
    "            Y_pred_train_proba.append(base_model.predict_proba(X_train_bagged)[:, 1])\n",
    "            Y_pred_val.append(base_model.predict(X_val))\n",
    "            Y_pred_val_proba.append(base_model.predict_proba(X_val)[:, 1])\n",
    "\n",
    "        Y_pred_train = majority_vote(Y_pred_train)\n",
    "        Y_pred_train_proba = np.mean(Y_pred_train_proba, axis=0)\n",
    "        Y_pred_val = majority_vote(Y_pred_val)\n",
    "        Y_pred_val_proba = np.mean(Y_pred_val_proba, axis=0)\n",
    "\n",
    "        # print(f\"Y_pred_train: {Y_pred_train}\")\n",
    "        metrics['train_accuracy'].append(accuracy_score(Y_train_bagged, Y_pred_train))\n",
    "        metrics['train_f1'].append(f1_score(Y_train_bagged, Y_pred_train))\n",
    "        metrics['train_precision'].append(precision_score(Y_train_bagged, Y_pred_train, zero_division=0))\n",
    "        metrics['train_recall'].append(recall_score(Y_train_bagged, Y_pred_train))\n",
    "        metrics['val_auc'].append(roc_auc_score(Y_train, Y_pred_train_proba))\n",
    "\n",
    "        metrics['val_accuracy'].append(accuracy_score(Y_val, Y_pred_val))\n",
    "        metrics['val_f1'].append(f1_score(Y_val, Y_pred_val))\n",
    "        metrics['val_fb'].append(fbeta_score(Y_val, Y_pred_val, beta=2))\n",
    "        metrics['val_precision'].append(precision_score(Y_val, Y_pred_val, zero_division=0))\n",
    "        metrics['val_recall'].append(recall_score(Y_val, Y_pred_val))\n",
    "        metrics['val_specificity'].append(specificity_score(Y_val, Y_pred_val))\n",
    "        metrics['val_auc'].append(roc_auc_score(Y_val, Y_pred_val_proba))\n",
    "        if self.modality.mode not in ['train', 'eval', 'feature', 'deploy', 'eval_val']:\n",
    "            if model_type in ['MLP', 'XGB']:\n",
    "                metrics['stopping_epoch'].append(base_model.best_iteration)\n",
    "            elif model_type in ['TAB', 'TABold']:\n",
    "                best_epoch = np.argmax(base_model.history['test_logloss'])\n",
    "                metrics['stopping_epoch'].append(best_epoch)\n",
    "            elif model_type == 'CAT':\n",
    "                metrics['stopping_epoch'].append(base_model.best_iteration_)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        return models\n",
    "\n",
    "    def average_metrics_across_folds(self, metrics):\n",
    "        return {key: statistics.mean(values) for key, values in metrics.items() if values}\n",
    "\n",
    "    def train_and_metric_module(self,\n",
    "        batch_size: int,\n",
    "        model_type: str,\n",
    "        feature_combination_str: str = None,\n",
    "        **kwargs) -> ModuleResults:\n",
    "\n",
    "        metrics = {\n",
    "            'train_accuracy': [], 'val_accuracy': [],\n",
    "            'train_f1': [], 'val_f1': [],\n",
    "            'val_fb': [],\n",
    "            'train_precision': [], 'val_precision': [],\n",
    "            'train_recall': [], 'val_recall': [],\n",
    "            'val_specificity': [],\n",
    "            'val_auc': [],\n",
    "            'stopping_epoch':[]\n",
    "        }\n",
    "\n",
    "        extra_fitting_params = {}\n",
    "\n",
    "        if model_type =='MLP':\n",
    "            model = myMlpModel(\n",
    "                max_epoch=kwargs.get('max_epoch'),\n",
    "                batch_size=kwargs.get('batch_size'),\n",
    "                device=kwargs.get('device'),\n",
    "                input_dim=kwargs.get('input_dim'),\n",
    "                n_classes=kwargs.get('n_classes'),\n",
    "                model_depth=kwargs.get('model_depth'),\n",
    "                model_width=kwargs.get('model_width'),\n",
    "                criterion=kwargs.get('criterion'),\n",
    "                model_dr=kwargs.get('model_dr'),\n",
    "                model_lr=kwargs.get('model_lr'),\n",
    "                l1_weight=kwargs.get('l1_weight'),\n",
    "                l2_weight=kwargs.get('l2_weight'),\n",
    "                weight_decay=kwargs.get('weight_decay'),\n",
    "                activation_function=kwargs.get('activation_function'),\n",
    "                patience=kwargs.get('patience'),\n",
    "                random_state=self.modality.random_state\n",
    "            )\n",
    "        elif model_type in ['TAB', 'TABold']:\n",
    "            # print(f'{kwargs.get('cat_idxs')}, {kwargs.get('cat_dims')}')\n",
    "\n",
    "            model = TabNetClassifier(\n",
    "                n_d = kwargs.get('width_prediction_and_attention'),\n",
    "                n_a = kwargs.get('width_prediction_and_attention'),\n",
    "                n_steps = kwargs.get('n_steps'),\n",
    "                gamma = kwargs.get('gamma'),\n",
    "                cat_idxs = kwargs.get('cat_idxs'),\n",
    "                cat_dims = kwargs.get('cat_dims'),\n",
    "                n_independent = kwargs.get('n_independent'),\n",
    "                n_shared = kwargs.get('n_shared'),\n",
    "                momentum = kwargs.get('momentum'),\n",
    "                lambda_sparse = kwargs.get('lambda_sparse'),\n",
    "                mask_type = kwargs.get('mask_type'),\n",
    "                seed=self.modality.random_state,\n",
    "                verbose=0,\n",
    "                device_name=device\n",
    "            )\n",
    "        elif model_type == \"SVM\":\n",
    "            model = SVC(\n",
    "                probability=True,\n",
    "                C=kwargs.get('c'),\n",
    "                kernel=kwargs.get('kernel'),\n",
    "                gamma=kwargs.get('gamma'),\n",
    "                tol=kwargs.get('tol'),\n",
    "                max_iter=kwargs.get('max_iter'),\n",
    "                degree=kwargs.get('degree'),\n",
    "                random_state=self.modality.random_state\n",
    "            )\n",
    "        elif model_type == \"KNN\": #* no random state required as it is deterministic\n",
    "            model = KNeighborsClassifier(\n",
    "                n_neighbors=kwargs.get('n_neighbors'),\n",
    "                weights=kwargs.get('weights'),\n",
    "                algorithm=kwargs.get('algorithm'),\n",
    "                leaf_size=kwargs.get('leaf_size'),\n",
    "                p=kwargs.get('p'),\n",
    "                metric=kwargs.get('metric'),\n",
    "            )\n",
    "        elif model_type == \"RF\":\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=kwargs.get('num_tree'),\n",
    "                criterion=kwargs.get('criterion'),\n",
    "                max_depth=kwargs.get('max_depth'),\n",
    "                min_samples_split=kwargs.get('min_sample_split'),\n",
    "                min_samples_leaf=kwargs.get('min_sample_leaf'),\n",
    "                max_features=kwargs.get('max_feature'),\n",
    "                max_leaf_nodes=kwargs.get('max_leaf_node'),\n",
    "                bootstrap=kwargs.get('bootstrap'),\n",
    "                min_impurity_decrease=kwargs.get('min_impurity_decrease'),\n",
    "                ccp_alpha=kwargs.get('ccp_alpha'),\n",
    "                max_samples=kwargs.get('max_samples'),\n",
    "                random_state=self.modality.random_state\n",
    "            )\n",
    "        elif model_type == \"XGB\":\n",
    "            model = XGBClassifier(\n",
    "                n_estimators=kwargs.get('n_estimators'),\n",
    "                eta=kwargs.get('eta'),\n",
    "                gamma=kwargs.get('gamma'),\n",
    "                max_depth=kwargs.get('max_depth'),\n",
    "                min_child_weight=kwargs.get('min_child_weight'),\n",
    "                subsample=kwargs.get('subsample'),\n",
    "                sampling_method=kwargs.get('sampling_method'),\n",
    "                reg_lambda=kwargs.get('reg_lambda'),\n",
    "                reg_alpha=kwargs.get('reg_alpha'),\n",
    "                grow_policy=kwargs.get('grow_policy'),\n",
    "                max_leaves=kwargs.get('max_leaves'),\n",
    "                early_stopping_rounds=kwargs.get('early_stopping_rounds'),\n",
    "                verbosity=0,\n",
    "                random_state=self.modality.random_state\n",
    "            )\n",
    "        elif model_type == \"CAT\":\n",
    "            print(f'Number of iterations set: {kwargs.get('iterations')}')\n",
    "            model = CatBoostClassifier(\n",
    "                iterations=kwargs.get('iterations'),\n",
    "                learning_rate=kwargs.get('learning_rate'),\n",
    "                depth=kwargs.get('depth'),\n",
    "                l2_leaf_reg=kwargs.get('l2_leaf_reg'),\n",
    "                early_stopping_rounds=kwargs.get('early_stopping_rounds'),\n",
    "                random_strength=kwargs.get('random_strength'),\n",
    "                colsample_bylevel=kwargs.get('colsample_bylevel'),\n",
    "                bagging_temperature=kwargs.get('bagging_temperature'),\n",
    "                border_count=kwargs.get('border_count'),\n",
    "                cat_features=kwargs.get('cat_features'),\n",
    "                eval_metric='AUC',\n",
    "                verbose=False,\n",
    "                random_seed=self.modality.random_state\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"model_type must be 'RF', 'KNN', 'XGB', or 'SVM'\")\n",
    "        \n",
    "        n_base_models = kwargs.get('n_base_models')\n",
    "\n",
    "        for fold, (X_train, Y_train, X_val, Y_val) in enumerate(self.kfold_loaders(model_type=model_type)):\n",
    "            models = []\n",
    "            for base_model_idx in range(n_base_models):\n",
    "                base_model = copy.deepcopy(model)\n",
    "                models.append(base_model)\n",
    "            models = self.fit_and_compute_metrics(models, model_type, X_train, Y_train, X_val, Y_val, metrics, **extra_fitting_params)\n",
    "\n",
    "        average_metrics = self.average_metrics_across_folds(metrics)\n",
    "\n",
    "        module_results = ModuleResults(\n",
    "            trained_models=models,\n",
    "            **average_metrics\n",
    "        )\n",
    "\n",
    "        return module_results\n",
    "    \n",
    "    def check_folder_structure(self, check_target:str):\n",
    "        dataset_len = 14\n",
    "        model_len = 3\n",
    "        feature_combination_len = 15\n",
    "        trial_len = 26\n",
    "        file_len = 29\n",
    "        \n",
    "        dataset = self.data.raw_dataset_name\n",
    "\n",
    "        dataset_folder = Path(f'{check_target}/{dataset}')\n",
    "\n",
    "        model_class_folders = [f for f in dataset_folder.iterdir() if f.is_dir()]\n",
    "        if len(model_class_folders) != 7:\n",
    "            print(f'Error: Folder {dataset} contains {len(model_class_folders)} subfolders, expected 7')\n",
    "            return False\n",
    "        \n",
    "        for model_class_folder in model_class_folders:\n",
    "\n",
    "            if model_class_folder.name in ['CAT', 'TAB']:\n",
    "                continue\n",
    "\n",
    "            feature_combination_folders = [f for f in model_class_folder.iterdir() if f.is_dir()]\n",
    "        \n",
    "            if model_class_folder.name not in ['TAB', 'TABold'] and len(feature_combination_folders) != 31:\n",
    "                print(f'Error: Folder {model_class_folder} contains {len(feature_combination_folders)} subfolders, expected 31')\n",
    "                return False\n",
    "            elif model_class_folder.name in ['TAB', 'TABold'] and len(feature_combination_folders) != 1:\n",
    "                print(f'Error: Folder {model_class_folder} contains {len(feature_combination_folders)} subfolders, expected 1')\n",
    "                return False\n",
    "            \n",
    "            for feature_combination_folder in feature_combination_folders:\n",
    "                metric_folders = [f for f in feature_combination_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "                for metric_folder in metric_folders:\n",
    "                    \n",
    "                    if metric_folder.name == self.modality.metric:\n",
    "                        seed_folders = [f for f in metric_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "                        for seed_folder in seed_folders:\n",
    "                            \n",
    "                            if seed_folder.name != f'seed_{self.modality.random_state+self.data.data_split_random_seed_modfier}':\n",
    "                                continue\n",
    "\n",
    "                            trial_folders = [f for f in seed_folder.iterdir() if f.is_dir()]\n",
    "                            \n",
    "                            if len(trial_folders) != 1:\n",
    "                                print(f'Error: Folder {seed_folder} contains {len(trial_folders)} folders, expected 1')\n",
    "                                return False\n",
    "\n",
    "                            for trial_folder in trial_folders:\n",
    "                                \n",
    "                                files = [f for f in trial_folder.iterdir() if f.is_file()]\n",
    "                                \n",
    "                                if len(files) != 1:\n",
    "                                    print(f\"Error: Folder {feature_combination_folder} contains {len(files)} .txt files, expected 1\")\n",
    "                                    return False\n",
    "\n",
    "                                # for file in files:\n",
    "                                #     print(f'{dataset:<{dataset_len}} | {model_class_folder.name:<{model_len}} | {feature_combination_folder.name:<{feature_combination_len}} | {trial_folder.name:<{trila_len}} | {file.name:<{file_len}}')\n",
    "                                \n",
    "                                if trial_folder.name.startswith('final_'): \n",
    "                                    new_name = trial_folder.parent / f\"final_{trial_folder.name}\".strip('final_')\n",
    "                                    try:\n",
    "                                        trial_folder.rename(new_name)\n",
    "                                    except FileExistsError:\n",
    "                                        print(f\"Error: Cannot rename {trial_folder} to {new_name} because the target file already exists\")\n",
    "                                        return False\n",
    "                                    except PermissionError:\n",
    "                                        print(f\"Error: Permission denied when renaming {trial_folder} to {new_name}\")\n",
    "                                        return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def finalize_trials(self, check_target:str):\n",
    "\n",
    "        models_stored = []\n",
    "\n",
    "        dataset_folder = Path(f'{check_target}/{self.data.raw_dataset_name}')\n",
    "        model_class_folders = [f for f in dataset_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "        for model_class_folder in model_class_folders:\n",
    "            \n",
    "            if model_class_folder.name in ['CAT', 'TAB']:\n",
    "                continue\n",
    "            \n",
    "            feature_combination_folders = [f for f in model_class_folder.iterdir() if f.is_dir()]\n",
    "        \n",
    "            for feature_combination_folder in feature_combination_folders:\n",
    "                metric_folders = [f for f in feature_combination_folder.iterdir() if f.is_dir()]\n",
    "                \n",
    "                for metric_folder in metric_folders:\n",
    "                    if metric_folder.name == self.modality.metric:\n",
    "\n",
    "                        seed_folders = [f for f in metric_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "                        for seed_folder in seed_folders:\n",
    "                            \n",
    "                            if seed_folder.name != f'seed_{self.modality.random_state+self.data.data_split_random_seed_modfier}':\n",
    "                                continue\n",
    "\n",
    "                            trial_folders = [f for f in seed_folder.iterdir() if f.is_dir()]\n",
    "                            for trial_folder in trial_folders:\n",
    "                                if not trial_folder.name.startswith('final_'): \n",
    "                                    new_name = trial_folder.parent / f\"final_{trial_folder.name}\"\n",
    "                                    try:\n",
    "                                        trial_folder.rename(new_name)\n",
    "                                    except FileExistsError:\n",
    "                                        print(f\"Error: Cannot rename {trial_folder} to {new_name} because the target file already exists\")\n",
    "                                    except PermissionError:\n",
    "                                        print(f\"Error: Permission denied when renaming {trial_folder} to {new_name}\")\n",
    "                                    trial_folder = new_name\n",
    "                                # print(trial_folder)\n",
    "                                files = [f for f in trial_folder.iterdir() if f.is_file()]\n",
    "                                model_and_info = {\n",
    "                                    'dataset': self.data.raw_dataset_name,\n",
    "                                    'model class': model_class_folder.name,\n",
    "                                    'feature combination': feature_combination_folder.name,\n",
    "                                    'model': files[0]\n",
    "                                }\n",
    "                                models_stored.append(model_and_info)\n",
    "\n",
    "        return models_stored if check_target == '../Model Evaluation' else []\n",
    "    \n",
    "    def scan_best_accuracy(self, root_path, model_type, feature_combination):\n",
    "        pattern = rf\"Best value \\({self.modality.metric}\\):\\s*([0-1]?\\.\\d+)\"\n",
    "        dataset = self.data.raw_dataset_name\n",
    "        dataset_folder = Path(f'{root_path}/{dataset}')\n",
    "        model_class_folders = [f for f in dataset_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "        for model_class_folder in model_class_folders:\n",
    "            feature_combination_folders = [f for f in model_class_folder.iterdir() if f.is_dir()]\n",
    "        \n",
    "            for feature_combination_folder in feature_combination_folders:\n",
    "                metric_folders = [f for f in feature_combination_folder.iterdir() if f.is_dir()]\n",
    "                \n",
    "                for metric_folder in metric_folders:\n",
    "                    if metric_folder.name == self.modality.metric:\n",
    "                        seed_folders = [f for f in metric_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "                        for seed_folder in seed_folders:\n",
    "                            \n",
    "                            if seed_folder.name != f'seed_{self.modality.random_state+self.data.data_split_random_seed_modfier}':\n",
    "                                continue\n",
    "\n",
    "                            trial_folders = [f for f in seed_folder.iterdir() if f.is_dir()]\n",
    "\n",
    "                            for trial_folder in trial_folders:\n",
    "                                files = [f for f in trial_folder.iterdir() if f.is_file()]\n",
    "\n",
    "                                if model_class_folder.name == model_type and feature_combination_folder.name == feature_combination:\n",
    "                                    try:\n",
    "                                        with open(files[0], 'r', encoding='utf-8') as file:\n",
    "                                            content = file.read()\n",
    "                                            # Search for the float value after 'Best value (Acc):'\n",
    "                                            match = re.search(pattern, content)\n",
    "                                            if match:\n",
    "                                                accuracy = float(match.group(1))\n",
    "                                                results = accuracy\n",
    "                                            else:\n",
    "                                                results = None\n",
    "                                    except Exception as e:\n",
    "                                        print(files)\n",
    "                                        results = f\"Error reading file: {str(e)}\"\n",
    "                                        print(f\"Error in file {files[0]}: {str(e)}\")\n",
    "                                    return results\n",
    "        return float('-inf')\n",
    "\n",
    "    def load_models_by_type(self, models_to_load): #todo: maybe make device a pipelin attribute as well?\n",
    "        \n",
    "        for model_to_load in models_to_load:\n",
    "        \n",
    "            print(f'model_to_load: {model_to_load}')\n",
    "\n",
    "            self.data.columns_to_keep = string_to_list(model_to_load['feature combination'])\n",
    "            self.load_dataset()\n",
    "            self.modify_dataset()\n",
    "            self.split_dataset()\n",
    "            self.set_TrialInformation()\n",
    "\n",
    "            if model_to_load['model class'] == 'MLP':\n",
    "                checkpoint = torch.load(model_to_load['model'], map_location=device)\n",
    "                base_model = myMlpModel(\n",
    "                    max_epoch=checkpoint['max_epoch'],\n",
    "                    batch_size=128,\n",
    "                    device=torch.device(device),\n",
    "                    input_dim=checkpoint['input_dim'],\n",
    "                    n_classes=checkpoint['n_classes'],\n",
    "                    model_depth=checkpoint['model_depth'],\n",
    "                    model_width=checkpoint['model_width'],\n",
    "                    model_dr=checkpoint['dropout_rate'],\n",
    "                    criterion=loss_function_dict['cross_entropy'] if checkpoint['criterion'] == 'cross_entropy' else checkpoint['criterion'],          # improve this\n",
    "                    model_lr=checkpoint['model_lr'],\n",
    "                    l1_weight=checkpoint['l1_weight'],\n",
    "                    l2_weight=checkpoint['l2_weight'],\n",
    "                    weight_decay=checkpoint['weight_decay'],\n",
    "                    patience=checkpoint.get('patience'),\n",
    "                    activation_function=checkpoint['activation_function'],\n",
    "                    random_state=self.modality.random_state\n",
    "                )\n",
    "                try:\n",
    "                    base_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    base_model.to(device)\n",
    "                    base_model.eval()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading MLP model {model_to_load['model']}: {e}\")\n",
    "            elif model_to_load['model class'] in ['TAB', 'TABold']:\n",
    "                try: \n",
    "                    categorical_idxs = [self.data.columns_remaining.index(5)] if '5' in self.data.columns_remaining_str else []\n",
    "                    categorical_dims = [2] if categorical_idxs else []\n",
    "                    base_model = TabNetClassifier(cat_idxs=categorical_idxs, cat_dims=categorical_dims)\n",
    "                    base_model.load_model(model_to_load['model'])\n",
    "                    base_model.network.eval()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading TabNet model {model_to_load['model']}: {e}\")\n",
    "            elif model_to_load['model class'] in ['SVM', 'KNN', 'RF']:\n",
    "                try:\n",
    "                    base_model = joblib.load(model_to_load['model'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading sklearn model {model_to_load['model']}: {e}\")\n",
    "            elif model_to_load['model class'] == 'XGB':\n",
    "                try:\n",
    "                    base_model = xgb.XGBClassifier()\n",
    "                    base_model.load_model(model_to_load['model'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading XGB model {model_to_load['model']}: {e}\")\n",
    "            elif model_to_load['model class'] == 'CAT':\n",
    "                try:\n",
    "                    base_model = CatBoostClassifier()\n",
    "                    base_model.load_model(model_to_load['model'], format='cbm')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading CAT model {model_to_load['model']}: {e}\")\n",
    "    \n",
    "            for fold, (X_train, Y_train, X_val, Y_val) in enumerate(self.kfold_loaders(model_type=model_to_load['model class'])):\n",
    "                \n",
    "                metrics = {\n",
    "                    'train_accuracy': [], 'val_accuracy': [],\n",
    "                    'train_f1': [], 'val_f1': [],\n",
    "                    'val_fb': [],\n",
    "                    'train_precision': [], 'val_precision': [],\n",
    "                    'train_recall': [], 'val_recall': [],\n",
    "                    'val_specificity': [],\n",
    "                    'val_auc': [],\n",
    "                    'stopping_epoch':[]\n",
    "                }\n",
    "                self.fit_and_compute_metrics(models=[base_model], model_type=model_to_load['model class'], X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, metrics=metrics)\n",
    "            \n",
    "            average_metrics = self.average_metrics_across_folds(metrics)\n",
    "            module_results = ModuleResults(\n",
    "                trained_models=None,\n",
    "                **average_metrics\n",
    "            )\n",
    "\n",
    "            if self.modality.mode in ['eval_val', 'eval']:\n",
    "\n",
    "                set_name = 'Test' if self.modality.mode == 'eval' else 'Val' if self.modality.mode == 'eval_val' else None\n",
    "                \n",
    "                model_to_load[f'Val {self.modality.metric}'] = self.scan_best_accuracy('../Hyperparameter tuning/Optuna', model_to_load['model class'], model_to_load['feature combination'])\n",
    "                model_to_load[f'{set_name} Acc'] = average_metrics['val_accuracy']\n",
    "                model_to_load[f'{set_name} F1'] = average_metrics['val_f1']\n",
    "                model_to_load[f'{set_name} F2'] = average_metrics['val_fb']\n",
    "                model_to_load[f'{set_name} AUC'] = average_metrics['val_auc']\n",
    "\n",
    "            elif self.modality.mode == 'deploy':\n",
    "\n",
    "                model_to_load[f'{self.data.raw_dataset_name} Acc'] = average_metrics['val_accuracy']\n",
    "                model_to_load[f'{self.data.raw_dataset_name} F1'] = average_metrics['val_f1']\n",
    "                model_to_load[f'{self.data.raw_dataset_name} F2'] = average_metrics['val_fb']\n",
    "                model_to_load[f'{self.data.raw_dataset_name} AUC'] = average_metrics['val_auc']\n",
    "\n",
    "        return models_to_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Optuna Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, pipeline:Pipeline, model_config_idx:int):\n",
    "    \n",
    "    model_config = pipeline.model_configs[model_config_idx]\n",
    "    search_space = model_config.search_space\n",
    "    model_type = model_config.model_type\n",
    "\n",
    "    param_space = {}\n",
    "    if model_type == \"MLP\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'model_lr': {'type': 'float', 'range': search_space.model_lr_range, 'log': True},\n",
    "            'model_dr': {'type': 'float', 'range': search_space.model_dr_range, 'log': False},\n",
    "            'l1_weight': {'type': 'float', 'range': search_space.l1_weight_range, 'log': True},\n",
    "            'l2_weight': {'type': 'float', 'range': search_space.l2_weight_range, 'log': True},\n",
    "            'model_depth': {'type': 'int', 'range': search_space.model_depth_range, 'step': search_space.optuna_step_for_model_depth},\n",
    "            'model_width': {'type': 'int', 'range': search_space.model_width_range, 'step': search_space.optuna_step_for_model_width},\n",
    "            'activation_function': {'type': 'categorical', 'range': search_space.activation_function_range},\n",
    "            'weight_decay': {'type': 'float', 'range': search_space.weight_decay_range, 'log': False},\n",
    "            'criterion': {'type': 'categorical', 'range': search_space.criterion_range},\n",
    "            'patience': {'type': 'int', 'range': search_space.patience_range, 'step': search_space.optuna_step_for_patience},\n",
    "            'max_epoch': {'type': 'categorical', 'range': [search_space.max_epoch_range]},\n",
    "            'device': {'type': 'categorical', 'range': [device]}, #todo: check if needed\n",
    "            'input_dim': {'type': 'categorical', 'range': [pipeline.data.X.shape[1]]},\n",
    "            'n_classes': {'type': 'categorical', 'range': [pipeline.data.n_classes]},\n",
    "        }\n",
    "    elif model_type == \"TAB\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'width_prediction_and_attention': {'type': 'int', 'range': search_space.width_prediction_and_attention_range},\n",
    "            'n_steps': {'type': 'int', 'range': search_space.n_step_range},\n",
    "            'gamma': {'type': 'float', 'range': search_space.gamma_range, 'log': False},\n",
    "            'n_independent': {'type': 'int', 'range': search_space.n_independent_range},\n",
    "            'n_shared': {'type': 'int', 'range': search_space.n_shared_range},\n",
    "            'momentum': {'type': 'float', 'range': search_space.momentum_range, 'log': True},\n",
    "            'lambda_sparse': {'type': 'float', 'range': search_space.lambda_sparse_range, 'log': True},\n",
    "            'mask_type': {'type': 'categorical', 'range': search_space.mask_type_range},\n",
    "        }\n",
    "    elif model_type == \"SVM\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'c': {'type': 'float', 'range': search_space.c_range, 'log': True},\n",
    "            'kernel': {'type': 'categorical', 'range': search_space.kernel_range},\n",
    "            'gamma': {'type': 'float', 'range': search_space.gamma_range, 'log': True},\n",
    "            'tol': {'type': 'float', 'range': search_space.tol_range, 'log': True},\n",
    "            'max_iter': {'type': 'int', 'range': search_space.max_iter_range}\n",
    "        }\n",
    "    elif model_type == \"KNN\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'n_neighbors': {'type': 'int', 'range': search_space.n_neighbor_range, 'step': search_space.optuna_step_for_n_neighbor},\n",
    "            'weights': {'type': 'categorical', 'range': search_space.weight_range},\n",
    "            'algorithm': {'type': 'categorical', 'range': search_space.algorithm_range},\n",
    "            'leaf_size': {'type': 'int', 'range': search_space.leaf_size_range, 'step': search_space.optuna_step_for_leaf_size, 'log': True},\n",
    "            # 'p': {'type': 'float', 'range': search_space.p_range},\n",
    "            'metric': {'type': 'categorical', 'range': search_space.metric_range}\n",
    "        }\n",
    "    elif model_type == \"RF\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'num_tree': {'type': 'int', 'range': search_space.num_tree_range, 'step': search_space.optuna_step_for_num_tree},\n",
    "            'criterion': {'type': 'categorical', 'range': search_space.criterion_range},\n",
    "            'max_depth': {'type': 'categorical', 'range': search_space.max_depth_range},\n",
    "            'min_sample_split': {'type': 'float', 'range': search_space.min_sample_split_range, 'log': True},\n",
    "            'min_sample_leaf': {'type': 'int', 'range': search_space.min_sample_leaf_range},\n",
    "            'max_feature': {'type': 'categorical', 'range': search_space.max_feature_range},\n",
    "            'max_leaf_node': {'type': 'categorical', 'range': search_space.max_leaf_node_range},\n",
    "            'bootstrap': {'type': 'categorical', 'range': search_space.bootstrap_range},\n",
    "            'min_impurity_decrease': {'type': 'float', 'range': search_space.min_impurity_decrease_range, 'log': True},\n",
    "            'ccp_alpha': {'type': 'float', 'range': search_space.ccp_alpha_range, 'log': True}\n",
    "        }\n",
    "    elif model_type == \"XGB\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'eta': {'type': 'float', 'range': search_space.eta_range, 'log': False},\n",
    "            'gamma': {'type': 'float', 'range': search_space.gamma_range, 'log': True},\n",
    "            'max_depth': {'type': 'int', 'range': search_space.max_depth_range, 'step': search_space.optuna_step_for_max_depth, 'log': True},\n",
    "            'min_child_weight': {'type': 'float', 'range': search_space.min_child_weight_range, 'log': True},\n",
    "            'subsample': {'type': 'float', 'range': search_space.subsample_range}, \n",
    "            'sampling_method': {'type': 'categorical', 'range': search_space.sampling_method_range},\n",
    "            'reg_lambda': {'type': 'float', 'range': search_space.reg_lambda_range, 'log': True},\n",
    "            'reg_alpha': {'type': 'float', 'range': search_space.reg_alpha_range, 'log': True},\n",
    "            'early_stopping_rounds' : {'type': 'int', 'range': search_space.early_stopping_rounds_range, 'log': True},\n",
    "            'grow_policy': {'type': 'categorical', 'range': search_space.grow_policy_range},\n",
    "            'max_leaves': {'type': 'int', 'range': search_space.max_leaf_range, 'step': search_space.optuna_step_for_max_depth, 'log': True}\n",
    "        }\n",
    "    elif model_type == \"CAT\":\n",
    "        param_space = {\n",
    "            'batch_size': {'type': 'int', 'range': search_space.batch_size_range, 'step': search_space.optuna_step_for_batch_size},\n",
    "            'learning_rate': {'type': 'float', 'range': search_space.learning_rate_range, 'log': True},\n",
    "            'depth': {'type': 'int', 'range': search_space.depth_range, 'step': search_space.optuna_step_for_depth},\n",
    "            'l2_leaf_reg': {'type': 'float', 'range': search_space.l2_leaf_reg_range, 'log': True},\n",
    "            'early_stopping_rounds': {'type': 'int', 'range': search_space.early_stopping_rounds_range, 'step': search_space.optuna_step_for_early_stopping_round},\n",
    "            'random_strength': {'type': 'float', 'range': search_space.random_strength_range},\n",
    "            'colsample_bylevel': {'type': 'float', 'range': search_space.colsample_range}, \n",
    "            'bagging_temperature': {'type': 'float', 'range': search_space.bagging_temperature_range},\n",
    "            'border_count': {'type': 'int', 'range': search_space.border_count_range}, \n",
    "        }\n",
    "        if '5' in pipeline.data.columns_remaining_str:\n",
    "            param_space['cat_features'] = {'type': 'categorical', 'range': [[pipeline.data.columns_remaining.index(5)]]} \n",
    "    if pipeline.modality.bagging_strategy == 'single':\n",
    "        param_space['n_base_models'] = {'type': 'int', 'range': pipeline.n_base_models}\n",
    "    if pipeline.modality.bagging_strategy == 'None':\n",
    "        param_space['n_base_models'] = {'type': 'int', 'range': [1]}\n",
    "\n",
    "    params = {}\n",
    "    for name, config in param_space.items():\n",
    "        params[name] = (\n",
    "            trial.suggest_int(name, config['range'][0], config['range'][-1], step=config.get('step', 1), log=config.get('log', False)) if config['type'] == 'int' else\n",
    "            trial.suggest_float(name, config['range'][0], config['range'][-1], log=config.get('log', False)) if config['type'] == 'float' else\n",
    "            trial.suggest_categorical(name, config['range'])\n",
    "        )\n",
    "\n",
    "    if pipeline.modality.bagging_strategy !='single':     # todo: improve logic here\n",
    "        params['n_base_models'] = 1\n",
    "    if model_type == 'MLP':\n",
    "        params['criterion'] = loss_function_dict[params['criterion']]\n",
    "    elif model_type in ['TAB', 'TABold']:\n",
    "        params['cat_idxs'] = [pipeline.data.columns_remaining.index(5)] if '5' in pipeline.data.columns_remaining_str else []\n",
    "        params['cat_dims'] = [2] if 'cat_idxs' in params else []\n",
    "    elif model_type == \"RF\":\n",
    "        params['max_samples'] = (\n",
    "            trial.suggest_float('max_samples', search_space.max_sample_range[0], search_space.max_sample_range[-1])\n",
    "            if params['bootstrap'] else None\n",
    "        )\n",
    "    elif model_type == \"KNN\":\n",
    "        params['p'] = (\n",
    "            trial.suggest_float('p', search_space.p_range[0], search_space.p_range[-1])\n",
    "            if params['metric'] == 'minkowski' else 2\n",
    "        )    \n",
    "    elif model_type == \"SVM\":\n",
    "        params['degree'] = (\n",
    "            trial.suggest_int('degree', search_space.degree_range[0], search_space.degree_range[-1], step=1)\n",
    "            if params['kernel'] == 'poly' else 1\n",
    "        )\n",
    "\n",
    "    module_results = pipeline.train_and_metric_module(model_type=model_type, **params)\n",
    "\n",
    "    if model_type in ['MLP', 'TAB', 'TABold', 'CAT', 'XGB']:\n",
    "        trial.set_user_attr('stopping_epoch', module_results.stopping_epoch)\n",
    "\n",
    "    if pipeline.modality.metric == 'Acc':\n",
    "        return module_results.val_accuracy\n",
    "    elif pipeline.modality.metric == 'F1':\n",
    "        return module_results.val_f1\n",
    "    elif pipeline.modality.metric == 'Fb':\n",
    "        return module_results.val_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters and user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI\n",
    "\n",
    "# The lists in the moodel section can each take 1 or more elements (arbitrary).\n",
    "# In training mode, only the 1st element in each list will be used.\n",
    "# In tuning, multiple elements will be used.\n",
    "#   - In optuna tuning, only the 1st and last element in the lists are taken and used to define the search range.\n",
    "#   - In grid searching, all elements are passed as search coordinates.\n",
    "\n",
    "# ---------------------------------- dataset --------------------------------- #\n",
    "\n",
    "GUI_raw_dataset_name = 'phpAmSP4g'\n",
    "GUI_raw_dataset_name = 'kc2'\n",
    "GUI_raw_dataset_name = 'gender'\n",
    "GUI_raw_dataset_name = 'tibial_slope_1'\n",
    "GUI_raw_dataset_name = 'tibial_slope_2'\n",
    "\n",
    "GUI_random_seed_modifier = 20\n",
    "GUI_random_seed_modifier = 0\n",
    "GUI_random_seed_modifier = 10\n",
    "\n",
    "GUI_train_ratio = 0.8\n",
    "GUI_n_classes = 2\n",
    "GUI_warm_up = 10\n",
    "GUI_patience = 10\n",
    "GUI_moving_average_range = 10000\n",
    "GUI_num_test = 10\n",
    "GUI_n_epochs = 500\n",
    "\n",
    "GUI_num_optuna_trials = 10000\n",
    "# ----------------------------------- modes ---------------------------------- #\n",
    "\n",
    "GUI_is_verbose = False\n",
    "\n",
    "GUI_saves_plot = True\n",
    "GUI_saves_plot = False\n",
    "\n",
    "GUI_uses_K_Fold = False\n",
    "GUI_uses_K_Fold = True\n",
    "\n",
    "GUI_is_developoer_test_mode = True\n",
    "\n",
    "GUI_uses_existing_model = False\n",
    "GUI_uses_existing_model = True\n",
    "\n",
    "GUI_uses_early_stopping = False \n",
    "GUI_uses_early_stopping = True\n",
    "\n",
    "GUI_standardizes_input = False\n",
    "GUI_standardizes_input = True\n",
    "\n",
    "GUI_bagging_strategy = 'diverse'\n",
    "GUI_bagging_strategy = 'single'\n",
    "GUI_bagging_strategy = 'None'\n",
    "    \n",
    "GUI_model_choice = 'TAB'\n",
    "GUI_model_choice = 'CAT'\n",
    "GUI_model_choice = 'XGB'\n",
    "GUI_model_choice = 'SVM'\n",
    "GUI_model_choice = 'MLP'\n",
    "GUI_model_choice = 'RF'\n",
    "GUI_model_choice = 'KNN'  \n",
    "\n",
    "GUI_mode = None \n",
    "GUI_mode = 'feature'  \n",
    "GUI_mode = 'deploy'     #! make sure only running on one feature combination\n",
    "GUI_mode = 'optuna'\n",
    "GUI_mode = 'check'\n",
    "GUI_mode = 'train' \n",
    "GUI_mode = 'eval'       #! make sure only running on one feature combination\n",
    "all_combinations =[[1, 2, 3, 4, 5]] if (GUI_model_choice in ['TAB', 'TABold'] or GUI_mode in ['deploy', 'eval']) else all_combinations\n",
    "\n",
    "GUI_metric = 'Fb'\n",
    "GUI_metric = 'Acc'\n",
    "GUI_metric = 'F1'\n",
    "\n",
    "GUI_reg = 'dropout'\n",
    "GUI_reg = 'L1_L2'\n",
    "\n",
    "device = 'cuda'\n",
    "device = 'cpu'\n",
    "\n",
    "# ----------------------------------- model ---------------------------------- #\n",
    "\n",
    "GUI_batch_sizes = [128, 128]\n",
    "GUI_n_base_models = [2, 10]\n",
    "GUI_drop_columns = False\n",
    "\n",
    "GUI_mlp_num_steps_width = 20\n",
    "GUI_mlp_step_size_width = 1\n",
    "GUI_mlp_lrs = [1e-7, 1]\n",
    "GUI_mlp_weight_decays = [0, 2]\n",
    "GUI_mlp_activation_functions = ['relu', 'tanh', 'elu', 'leaky relu', 'log sigmoid', 'continuous relu', 'relu 6', 'gaussian relu', 'sigmoid', 'sigmoid relu']\n",
    "GUI_mlp_activation_functions = ['relu 6', 'tanh', 'relu']\n",
    "GUI_mlp_criterions = ['L1', 'MSE', 'cross entropy', 'NLL', 'CTC', 'KL divergence', 'BCE logit']\n",
    "GUI_mlp_criterions = ['cross entropy']\n",
    "GUI_mlp_depths = [1, 3]\n",
    "GUI_mlp_widths = [GUI_mlp_step_size_width + 1, GUI_mlp_num_steps_width * GUI_mlp_step_size_width + 1]\n",
    "GUI_mlp_patience = [1, 100]\n",
    "\n",
    "GUI_tab_width_prediction_and_attention = [8, 64]\n",
    "GUI_tab_n_steps = [3, 10]\n",
    "GUI_tab_gamma = [1.0, 2.0]\n",
    "GUI_tab_cat_dims = [4]\n",
    "GUI_tab_cat_dims = [2]\n",
    "GUI_tab_n_independent = [1, 5]\n",
    "GUI_tab_n_shared = [1, 5]\n",
    "GUI_tab_momentum = [1e-2, 0.4]\n",
    "GUI_tab_lambda_sparse = [1e-5, 1e-1]\n",
    "GUI_tab_mask_type = ['sparsemax', 'entmax']\n",
    "\n",
    "GUI_rf_num_trees = [2, 100]\n",
    "GUI_rf_criterions = ['gini']\n",
    "GUI_rf_max_depths = list(range(1, 21)) + [None]\n",
    "GUI_rf_min_sample_split = [0.02, 1.0]\n",
    "GUI_rf_min_sample_leaf = [1, 10]  \n",
    "GUI_rf_max_features = ['sqrt', 'log2', None]\n",
    "GUI_rf_max_leaf_nodes = list(range(2, 101)) + [None]\n",
    "GUI_rf_bootstraps = [True, False]\n",
    "GUI_rf_min_impurity_decrease = [1e-7, 1e7]\n",
    "GUI_rf_ccp_alpha = [1e-7, 1e7]\n",
    "GUI_rf_max_samples = [0.1, 1.0]\n",
    "GUI_mlp_drs = [0, 1]\n",
    "GUI_mlp_l1_weight = [1e-7, 1e2]\n",
    "GUI_mlp_l2_weight = [1e-7, 1e2]\n",
    "\n",
    "GUI_knn_n_neighbors = [1, 15]\n",
    "GUI_knn_weights = ['uniform', 'distance']\n",
    "GUI_knn_algorithms = ['kd_tree', 'brute']\n",
    "GUI_knn_leaf_sizes = [1, 100]\n",
    "GUI_knn_ps = [1, 5]\n",
    "GUI_metrics = ['minkowski']\n",
    "\n",
    "GUI_xgb_etas = [0, 1]\n",
    "GUI_xgb_gammas = [1e-7, 10000]\n",
    "GUI_xgb_max_depths = [1, 100]\n",
    "GUI_xgb_min_child_weights = [1e-7, 10000]\n",
    "GUI_xgb_subsamples = [0.1, 1.0]\n",
    "GUI_xgb_sampling_methods = ['uniform']\n",
    "GUI_xgb_reg_lambdas = [1e-7, 10000]\n",
    "GUI_xgb_reg_alphas = [1e-7, 10000]\n",
    "GUI_grow_policies = ['depthwise', 'lossguide']\n",
    "GUI_xgb_max_leaves = [1, 10000]\n",
    "GUI_xgb_early_stopping_rounds = [1e1, 1e2]\n",
    "\n",
    "GUI_svm_c = [1e-5, 1e5]\n",
    "GUI_svm_kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "GUI_svm_gamma = [1e-5, 1e5]\n",
    "GUI_svm_tol = [1e-6, 1e-2]\n",
    "GUI_svm_max_iter = [1e1, 1e6]\n",
    "GUI_svm_degree = [2, 5]\n",
    "\n",
    "GUI_cat_eval_metric = ['Accuracy']\n",
    "GUI_cat_features = [[4]]\n",
    "GUI_cat_early_stopping_rounds = [1e1, 1e2]\n",
    "GUI_cat_learning_rate = [1e-3, 0.5]\n",
    "GUI_cat_depth = [4, 10]\n",
    "GUI_cat_l2_leaf_reg = [1e-2, 1e2]\n",
    "GUI_cat_random_strength = [0, 10]\n",
    "GUI_cat_colsample = [0.4, 1.0]\n",
    "GUI_cat_bagging_temperature = [0, 1]\n",
    "GUI_cat_border_count = [32, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search_space_registry = {\n",
    "    \"mlp\": MLP_SearchSpace,\n",
    "    \"tab\": TAB_SearchSpace,\n",
    "    \"rf\": RF_SearchSpace,\n",
    "    \"svm\": SVM_SearchSpace,\n",
    "    \"xgb\": XGB_SearchSpace,\n",
    "    \"knn\": KNN_SearchSpace,\n",
    "    \"cat\": CAT_SearchSpace\n",
    "}\n",
    "\n",
    "user_defined_search_spaces = {\n",
    "    \"MLP\": {\n",
    "        \"max_epoch_range\": GUI_n_epochs,\n",
    "        \"batch_size_range\": GUI_batch_sizes, \n",
    "        \"model_depth_range\": GUI_mlp_depths, \n",
    "        \"model_width_range\": GUI_mlp_widths, \n",
    "        \"model_lr_range\": GUI_mlp_lrs, \n",
    "        \"model_dr_range\": GUI_mlp_drs, \n",
    "        \"activation_function_range\": GUI_mlp_activation_functions, \n",
    "        \"weight_decay_range\": GUI_mlp_weight_decays, \n",
    "        \"criterion_range\": GUI_mlp_criterions,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials, # todo: check if the num_optuna_trials in MLP and other models are actually needed\n",
    "        \"patience_range\": GUI_mlp_patience,\n",
    "        \"l1_weight_range\": GUI_mlp_l1_weight,\n",
    "        \"l2_weight_range\": GUI_mlp_l2_weight\n",
    "    },\n",
    "    \"TAB\": {\n",
    "        \"batch_size_range\": GUI_batch_sizes,\n",
    "        \"width_prediction_and_attention_range\": GUI_tab_width_prediction_and_attention,\n",
    "        \"n_step_range\": GUI_tab_n_steps,\n",
    "        \"gamma_range\": GUI_tab_gamma,\n",
    "        \"cat_idx_range\": GUI_tab_cat_dims,\n",
    "        \"cat_dim_range\": GUI_tab_cat_dims,\n",
    "        \"n_independent_range\": GUI_tab_n_independent,\n",
    "        \"n_shared_range\": GUI_tab_n_shared,\n",
    "        \"momentum_range\": GUI_tab_momentum,\n",
    "        \"lambda_sparse_range\": GUI_tab_lambda_sparse,\n",
    "        \"mask_type_range\": GUI_tab_mask_type,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials\n",
    "        # \"patience_range\": List[int]\n",
    "        # \"optimizer_param_range\": List[float]\n",
    "        # \"max_epoch_range\": List[int]\n",
    "        # \"max_epoch_range\": List[int]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"batch_size_range\": GUI_batch_sizes,\n",
    "        \"c_range\": GUI_svm_c,\n",
    "        \"kernel_range\": GUI_svm_kernel,\n",
    "        \"gamma_range\": GUI_svm_gamma,\n",
    "        \"tol_range\": GUI_svm_gamma,\n",
    "        \"max_iter_range\": GUI_svm_max_iter,\n",
    "        \"degree_range\": GUI_svm_degree,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        \"batch_size_range\": GUI_batch_sizes,\n",
    "        \"n_neighbor_range\": GUI_knn_n_neighbors,\n",
    "        \"weight_range\": GUI_knn_weights,\n",
    "        \"algorithm_range\": GUI_knn_algorithms,\n",
    "        \"leaf_size_range\": GUI_knn_leaf_sizes,\n",
    "        \"p_range\": GUI_knn_ps,\n",
    "        \"metric_range\": GUI_metrics,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"batch_size_range\": GUI_batch_sizes,\n",
    "        \"num_tree_range\": GUI_rf_num_trees,\n",
    "        \"criterion_range\": GUI_rf_criterions,\n",
    "        \"max_depth_range\": GUI_rf_max_depths,\n",
    "        \"min_sample_split_range\": GUI_rf_min_sample_split,\n",
    "        \"min_sample_leaf_range\": GUI_rf_min_sample_leaf,\n",
    "        \"max_feature_range\": GUI_rf_max_features,\n",
    "        \"max_leaf_node_range\": GUI_rf_max_leaf_nodes,\n",
    "        \"bootstrap_range\": GUI_rf_bootstraps,\n",
    "        \"min_impurity_decrease_range\": GUI_rf_min_impurity_decrease,\n",
    "        \"ccp_alpha_range\": GUI_rf_ccp_alpha,\n",
    "        \"max_sample_range\": GUI_rf_max_samples,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials\n",
    "    },\n",
    "    \"XGB\": {\n",
    "        \"batch_size_range\": GUI_batch_sizes,\n",
    "        \"eta_range\": GUI_xgb_etas,\n",
    "        \"gamma_range\": GUI_xgb_gammas,\n",
    "        \"max_depth_range\": GUI_xgb_max_depths,\n",
    "        \"min_child_weight_range\": GUI_xgb_min_child_weights,\n",
    "        \"subsample_range\": GUI_xgb_subsamples,\n",
    "        \"sampling_method_range\": GUI_xgb_sampling_methods,\n",
    "        \"reg_lambda_range\": GUI_xgb_reg_lambdas,\n",
    "        \"reg_alpha_range\": GUI_xgb_reg_alphas,\n",
    "        \"early_stopping_rounds_range\": GUI_xgb_early_stopping_rounds,\n",
    "        \"grow_policy_range\": GUI_grow_policies,\n",
    "        \"max_leaf_range\": GUI_xgb_max_leaves,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials\n",
    "    },\n",
    "    \"CAT\": {\n",
    "        \"batch_size_range\": GUI_batch_sizes,\n",
    "        \"cat_features_range\": GUI_cat_features,\n",
    "        \"early_stopping_rounds_range\": GUI_cat_early_stopping_rounds,\n",
    "        \"learning_rate_range\": GUI_cat_learning_rate,\n",
    "        \"depth_range\": GUI_cat_depth,\n",
    "        \"l2_leaf_reg_range\": GUI_cat_l2_leaf_reg,\n",
    "        \"random_strength_range\": GUI_cat_random_strength,\n",
    "        \"colsample_range\": GUI_cat_colsample,\n",
    "        \"bagging_temperature_range\": GUI_cat_bagging_temperature,\n",
    "        \"border_count_range\": GUI_cat_border_count,\n",
    "        \"num_optuna_trials\": GUI_num_optuna_trials\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for GUI_columns_to_keep in all_combinations:\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.set_Modality(\n",
    "            mode=GUI_mode, \n",
    "            model_choice=GUI_model_choice,\n",
    "            metric=GUI_metric,\n",
    "            is_developer_test_mode=GUI_is_developoer_test_mode, \n",
    "            uses_K_Fold=GUI_uses_K_Fold, \n",
    "            uses_existing_model=GUI_uses_existing_model, \n",
    "            saves_plot=GUI_saves_plot, \n",
    "            is_verbose=GUI_is_verbose,\n",
    "            standardizes_input=GUI_standardizes_input,\n",
    "            uses_early_stopping=GUI_uses_early_stopping,\n",
    "            bagging_strategy=GUI_bagging_strategy,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        pipeline.set_Data(\n",
    "            raw_dataset_name=GUI_raw_dataset_name, \n",
    "            train_ratio=GUI_train_ratio, \n",
    "            n_classes=GUI_n_classes, \n",
    "            columns_to_keep=GUI_columns_to_keep,\n",
    "            data_split_random_seed_modfier=GUI_random_seed_modifier,\n",
    "        )\n",
    "        \n",
    "        pipeline.load_dataset()\n",
    "        pipeline.modify_dataset()\n",
    "        pipeline.split_dataset()\n",
    "        pipeline.set_TrialInformation()\n",
    "        pipeline.set_n_base_model_range(GUI_n_base_models)\n",
    "        \n",
    "        print(f'Dataset: {pipeline.data.raw_dataset_name}')\n",
    "        print(pipeline.modality)\n",
    "        print(pipeline.trial_info)\n",
    "\n",
    "        if pipeline.modality.bagging_strategy == 'single': \n",
    "            bagged_models = [pipeline.modality.model_choice]\n",
    "        elif pipeline.modality.bagging_strategy == 'diverse':\n",
    "            bagged_models = ['MLP', 'TAB', 'SVM', 'KNN', 'RF', 'XGB', 'CAT', 'TABold']\n",
    "        elif pipeline.modality.bagging_strategy == 'None':\n",
    "            bagged_models = [pipeline.modality.model_choice]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for pipeline.modality.model_choice. It should be 'single', 'diverse', or 'None'.\")\n",
    "\n",
    "        for i, model_type in enumerate(bagged_models):\n",
    "            config = user_defined_search_spaces[model_type] \n",
    "            pipeline.add_model_config(\n",
    "                model_type=model_type,\n",
    "                ensemble_group=\"group_1\",  \n",
    "                name=f\"Model_{i+1}\",  \n",
    "                **config\n",
    "            )\n",
    "        \n",
    "        print('All Models to Tune:')\n",
    "        pipeline.list_models()\n",
    "            \n",
    "        if pipeline.modality.mode == 'optuna':\n",
    "\n",
    "            print(\"\\nOptuna Tuning:\\n\")\n",
    "\n",
    "            for model_config_idx, model_config in enumerate(pipeline.model_configs):\n",
    "                \n",
    "                model_name = f'Bag model {model_config.name}'\n",
    "                print(f'Tuning {model_config.name}: {model_config.model_type}')\n",
    "                search_space = model_config.search_space\n",
    "\n",
    "                study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=random_state))\n",
    "                study.optimize(lambda trial: objective(trial, pipeline, model_config_idx), search_space.num_optuna_trials)\n",
    "\n",
    "                with open(check_for_file_duplicates_simple(pipeline.trial_info.hyperparam_save_path.replace(pipeline.modality.model_choice, model_config.model_type)), 'w') as file:\n",
    "\n",
    "                    if pipeline.modality.model_choice == 'MLP':\n",
    "                        file.write(f\"Regularization Option: {GUI_reg}\\n\\n\")\n",
    "\n",
    "                    file.write(f'Dataset: {pipeline.data.raw_dataset_name}')\n",
    "                    file.write(str(pipeline.modality))\n",
    "                    file.write(\"\\n\\n\")\n",
    "                    \n",
    "                    file.write(str(search_space))\n",
    "                    file.write(\"\\n\\n\")\n",
    "\n",
    "                    file.write(str(pipeline.trial_info))\n",
    "                    file.write(\"\\n\\n\")\n",
    "\n",
    "                    file.write(f'Feature_used (columns): {str(pipeline.data.columns_remaining)}')\n",
    "                    file.write(\"\\n\")\n",
    "                    file.write(f'Feature_used (compact): {pipeline.data.columns_remaining_str}')\n",
    "                    file.write(\"\\n\\n\")\n",
    "\n",
    "                    file.write(\"Optuna Tuning:\")\n",
    "                    file.write(\"\\n\\n\")\n",
    "                    file.write(f\"Best value ({pipeline.modality.metric}): {study.best_value}\")\n",
    "                    file.write(\"\\n\")\n",
    "                    file.write(f\"Best parameters: {study.best_params}\")\n",
    "\n",
    "                    if study.best_trial.user_attrs:\n",
    "                        file.write(\"\\n\\nAdditional Trial Attributes:\")\n",
    "                    for key, value in study.best_trial.user_attrs.items():\n",
    "                        file.write(f\"\\n{key}: {value}\")\n",
    "                    \n",
    "                print(f'Optuna files for model {pipeline.model_configs[model_config_idx].name} saved successfuly.')\n",
    "\n",
    "        elif pipeline.modality.mode in ['check', 'train']:\n",
    "            \n",
    "            optimal_hyperparam_directory = Path(pipeline.trial_info.hyperparam_save_path).parent.parent\n",
    "            \n",
    "            matching_folders = [p for p in Path(optimal_hyperparam_directory).iterdir() if p.is_dir() and p.name.startswith('final_')]\n",
    "            # matching_folders = [p for p in Path(optimal_hyperparam_directory).iterdir() if p.is_dir() and p.name.startswith('try_')]\n",
    "            \n",
    "            if not matching_folders:\n",
    "                raise FileNotFoundError(f\"No folder starting with 'final_' found in {optimal_hyperparam_directory}\")\n",
    "            \n",
    "            target_folder = matching_folders[0]\n",
    "\n",
    "            optimal_hyperparam_path = os.path.join(target_folder, f'{pipeline.modality.model_choice}_{pipeline.modality.metric}_{pipeline.data.columns_remaining}.txt')\n",
    "\n",
    "            with open(optimal_hyperparam_path, \"r\") as f:\n",
    "                content = f.read()\n",
    "\n",
    "            start_index = content.index(\"Optuna Tuning:\")\n",
    "            optuna_tuning = content[start_index:]\n",
    "            start_index = content.index(f\"{pipeline.modality.model_choice} Search Space\")\n",
    "            optuna_search_sapce = content[start_index:]\n",
    "\n",
    "            trials = re.findall(r'Best parameters: \\{(.*?)\\}', optuna_tuning)\n",
    "\n",
    "            best_hyper_params = {}  \n",
    "\n",
    "            for params in trials:\n",
    "                for param in params.split(\", \"):\n",
    "                    inner_key, val = param.split(\": \")\n",
    "                    inner_key = inner_key.strip(\"'\")\n",
    "                    if val.isdigit():\n",
    "                        best_hyper_params[inner_key] = float(val)\n",
    "                    else:\n",
    "                        best_hyper_params[inner_key] = val.strip(\"'\")\n",
    "\n",
    "            best_hyper_params['n_base_models'] = 1 if best_hyper_params.get(\"n_base_models\", None) is None else int(best_hyper_params.get('n_base_models', None))\n",
    "            best_tuned_performance = re.search(rf'Best value \\({pipeline.modality.metric}\\): (\\d+(?:\\.\\d+)?)', optuna_tuning)\n",
    "            rounds_tuning = re.search(r'num_optuna_trials: \\d+', optuna_search_sapce)\n",
    "            \n",
    "            if pipeline.modality.model_choice in ['MLP', 'TAB', 'TABold', 'CAT', 'XGB']:\n",
    "                stopping_epoch = re.search(r'stopping_epoch: (\\d+(?:\\.\\d+)?)', optuna_tuning)\n",
    "                stopping_epoch = round(float(stopping_epoch.group(1))) + 1\n",
    "                \n",
    "            if pipeline.modality.model_choice == 'MLP':\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                best_hyper_params['model_lr'] = float(best_hyper_params['model_lr'])\n",
    "                best_hyper_params['model_dr'] = float(best_hyper_params['model_dr'])\n",
    "                best_hyper_params['l1_weight'] = float(best_hyper_params['l1_weight'])\n",
    "                best_hyper_params['l2_weight'] = float(best_hyper_params['l2_weight'])\n",
    "                best_hyper_params['model_depth'] = int(best_hyper_params['model_depth'])\n",
    "                best_hyper_params['model_width'] = int(best_hyper_params['model_width'])\n",
    "                best_hyper_params['activation_function'] = best_hyper_params['activation_function'].strip(\"'\")\n",
    "                best_hyper_params['weight_decay'] = float(best_hyper_params['weight_decay'])\n",
    "                best_hyper_params['criterion'] = loss_function_dict[best_hyper_params['criterion'].strip(\"'\")]\n",
    "                # best_hyper_params['patience'] = int(best_hyper_params['patience']) if pipeline.modality.mode == 'check' else None\n",
    "                best_hyper_params['max_epoch'] = stopping_epoch if pipeline.modality.mode == 'train' else 500 #! hard coded\n",
    "                best_hyper_params['input_dim'] = int(best_hyper_params['input_dim'])\n",
    "                best_hyper_params['n_classes'] = int(best_hyper_params['n_classes'])\n",
    "            elif pipeline.modality.model_choice in ['TAB', 'TABold']:\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                # best_hyper_params['width_prediction'] = int(best_hyper_params['width_prediction_and_attention'])\n",
    "                # best_hyper_params['width_attention'] = int(best_hyper_params['width_prediction_and_attention'])\n",
    "                best_hyper_params['width_prediction_and_attention'] = int(best_hyper_params['width_prediction_and_attention'])\n",
    "                best_hyper_params['n_steps'] = int(best_hyper_params['n_steps'])\n",
    "                best_hyper_params['gamma'] = float(best_hyper_params['gamma'])\n",
    "                best_hyper_params['n_independent'] = int(best_hyper_params['n_independent'])\n",
    "                best_hyper_params['n_shared'] = int(best_hyper_params['n_shared'])\n",
    "                best_hyper_params['momentum'] = float(best_hyper_params['momentum'])\n",
    "                best_hyper_params['lambda_sparse'] = float(best_hyper_params['lambda_sparse'])\n",
    "                best_hyper_params['mask_type'] = best_hyper_params['mask_type'].strip(\"'\")\n",
    "                best_hyper_params['max_epoch'] = stopping_epoch if pipeline.modality.mode == 'train' else 200 #! hard coded\n",
    "                best_hyper_params['cat_idxs'] = [pipeline.data.columns_remaining.index(5)] if '5' in pipeline.data.columns_remaining_str else []\n",
    "                best_hyper_params['cat_dims'] = [2] if best_hyper_params['cat_idxs'] else []\n",
    "            elif pipeline.modality.model_choice == 'SVM':\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                best_hyper_params['c'] = float(best_hyper_params['c'])\n",
    "                best_hyper_params['kernel'] = (best_hyper_params['kernel']).strip(\"'\")\n",
    "                best_hyper_params['gamma'] = float(best_hyper_params['gamma'])\n",
    "                best_hyper_params['tol'] = float(best_hyper_params['tol'])\n",
    "                best_hyper_params['max_iter'] = int(best_hyper_params['max_iter'])\n",
    "                best_hyper_params['degree'] = 1 if best_hyper_params.get(\"degree\", None) is None else int(best_hyper_params.get(\"degree\", None))\n",
    "            elif pipeline.modality.model_choice == 'KNN':\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                best_hyper_params['n_neighbors'] = int(best_hyper_params['n_neighbors'])\n",
    "                best_hyper_params['weights'] = (best_hyper_params['weights']).strip(\"'\")\n",
    "                best_hyper_params['algorithm'] = (best_hyper_params['algorithm']).strip(\"'\")\n",
    "                best_hyper_params['leaf_size'] = int(best_hyper_params['leaf_size'])\n",
    "                best_hyper_params['p'] = float(best_hyper_params['p'])\n",
    "                best_hyper_params['metric'] = (best_hyper_params['metric']).strip(\"'\")\n",
    "            elif pipeline.modality.model_choice == 'RF':\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                best_hyper_params['num_tree'] = int(best_hyper_params['num_tree'])\n",
    "                best_hyper_params['criterion'] = (best_hyper_params['criterion']).strip(\"'\")\n",
    "                best_hyper_params['max_depth'] = None if best_hyper_params[\"max_depth\"] == 'None' else int(best_hyper_params['max_depth'])\n",
    "                best_hyper_params['min_sample_split'] = float(best_hyper_params['min_sample_split'])\n",
    "                best_hyper_params['min_sample_leaf'] = int(best_hyper_params['min_sample_leaf'])\n",
    "                best_hyper_params['max_feature'] = None if best_hyper_params['max_feature'] == 'None' else best_hyper_params['max_feature'].strip(\"'\")\n",
    "                best_hyper_params['max_leaf_node'] = None if best_hyper_params['max_leaf_node'] == 'None' else int(best_hyper_params['max_leaf_node'])\n",
    "                best_hyper_params['bootstrap'] = ast.literal_eval(best_hyper_params['bootstrap'])\n",
    "                best_hyper_params['min_impurity_decrease'] = float(best_hyper_params['min_impurity_decrease'])\n",
    "                best_hyper_params['ccp_alpha'] = float(best_hyper_params['ccp_alpha'])\n",
    "                best_hyper_params['max_samples'] = None if best_hyper_params.get(\"max_sample\", None) is None else float(best_hyper_params.get('max_sample', None))\n",
    "            elif pipeline.modality.model_choice == 'XGB':\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                best_hyper_params['eta'] = float(best_hyper_params['eta'])\n",
    "                best_hyper_params['gamma'] = float(best_hyper_params['gamma'])\n",
    "                best_hyper_params['max_depth'] = int(best_hyper_params['max_depth'])\n",
    "                best_hyper_params['min_child_weight'] = float(best_hyper_params['min_child_weight'])\n",
    "                best_hyper_params['subsample'] = float(best_hyper_params['subsample'])\n",
    "                best_hyper_params['sampling_method'] = (best_hyper_params['sampling_method']).strip(\"'\")\n",
    "                best_hyper_params['reg_lambda'] = float(best_hyper_params['reg_lambda'])\n",
    "                best_hyper_params['reg_alpha'] = float(best_hyper_params['reg_alpha'])\n",
    "                best_hyper_params['grow_policy'] = (best_hyper_params['grow_policy']).strip(\"'\")\n",
    "                best_hyper_params['max_leaves'] = int(best_hyper_params['max_leaves'])\n",
    "                best_hyper_params['n_estimators'] = stopping_epoch if pipeline.modality.mode == 'train' else None\n",
    "                best_hyper_params['early_stopping_rounds'] = int(best_hyper_params['early_stopping_rounds']) if pipeline.modality.mode == 'check' else None\n",
    "            elif pipeline.modality.model_choice == 'CAT':\n",
    "                best_hyper_params['batch_size'] = int(best_hyper_params['batch_size'])\n",
    "                best_hyper_params['learning_rate'] = float(best_hyper_params['learning_rate'])\n",
    "                best_hyper_params['depth'] = int(best_hyper_params['depth'])\n",
    "                best_hyper_params['l2_leaf_reg'] = float(best_hyper_params['l2_leaf_reg'])\n",
    "                best_hyper_params['random_strength'] = float(best_hyper_params['random_strength'])\n",
    "                best_hyper_params['colsample_bylevel'] = float(best_hyper_params['colsample_bylevel'])\n",
    "                best_hyper_params['bagging_temperature'] = float(best_hyper_params['bagging_temperature'])\n",
    "                best_hyper_params['border_count'] = int(best_hyper_params['border_count'])\n",
    "                best_hyper_params['iterations'] = stopping_epoch if pipeline.modality.mode == 'train' else None\n",
    "                best_hyper_params['early_stopping_rounds'] = int(best_hyper_params['early_stopping_rounds']) if pipeline.modality.mode == 'check' else None\n",
    "                best_hyper_params['cat_features'] = ast.literal_eval(best_hyper_params['cat_features']) if 'cat_features' in best_hyper_params else []\n",
    "                best_hyper_params['cat_features'] = [int(i) for i in best_hyper_params['cat_features']]\n",
    "\n",
    "            # print(best_hyper_params)\n",
    "            print(f'\\nA total of {best_hyper_params['n_base_models']} models read, tuned with {rounds_tuning.group(0)} trials.')\n",
    "            \n",
    "            module_results = pipeline.train_and_metric_module(model_type=pipeline.modality.model_choice, **best_hyper_params)\n",
    "            \n",
    "            print(f'\\n')\n",
    "            # print(f'Train Accuracy: {module_results.train_accuracy:.4f}')\n",
    "            # print(f'Train F1: {module_results.train_f1:.4f}')\n",
    "            # print(f'Train AUC: {module_results.train_auc:.4f}')\n",
    "            print(f'Test Accuracy: {module_results.val_accuracy:.4f}')\n",
    "            print(f'Test F1: {module_results.val_f1:.4f}')\n",
    "            print(f'Test AUC: {module_results.val_auc:.4f}')\n",
    "            \n",
    "            if pipeline.modality.mode == 'check':\n",
    "                \n",
    "                actual_performance = module_results.val_accuracy if pipeline.modality.metric == 'Acc' else module_results.val_f1 if pipeline.modality.metric == 'F1' else module_results.val_fb\n",
    "                check_tune_consistency(tuned_performance=float(best_tuned_performance.group(1)), actual_performance=actual_performance) \n",
    "            \n",
    "            elif pipeline.modality.mode == 'train':\n",
    "                \n",
    "                for model_idx, base_model in enumerate(module_results.trained_models):\n",
    "\n",
    "                    if pipeline.modality.model_choice == 'MLP':\n",
    "                        model_info = {\n",
    "                            'model_state_dict': base_model.state_dict(),\n",
    "                                \n",
    "                            'optimizer_state_dict': base_model.optimizer.state_dict(),\n",
    "                            \n",
    "                            'input_dim': base_model.fc_layers[0].in_features,\n",
    "                            'n_classes': base_model.fc_last.out_features,\n",
    "                            'model_width': base_model.fc_layers[0].out_features,\n",
    "                            'model_depth': len(base_model.fc_layers),\n",
    "                            'dropout_rate': base_model.dropout_layers[0].p,\n",
    "                            'criterion': base_model.criterion,\n",
    "                            'activation_function': base_model.activation_function,\n",
    "                            \n",
    "                            'model_lr': base_model.model_lr,\n",
    "                            'weight_decay': base_model.weight_decay,\n",
    "                            'l1_weight': base_model.l1_weight,\n",
    "                            'l2_weight': base_model.l2_weight,\n",
    "                            'random_state': base_model.random_state,\n",
    "                            \n",
    "                            'max_epoch': base_model.max_epoch,\n",
    "                        }\n",
    "                        torch.save(model_info, check_for_file_duplicates_short(os.path.splitext(pipeline.trial_info.model_save_path)[0], os.path.splitext(pipeline.trial_info.model_save_path)[1]))\n",
    "                    elif pipeline.modality.model_choice in ['TAB', 'TABold']:\n",
    "                        # torch.save(base_model.network, check_for_file_duplicates_short(os.path.splitext(pipeline.trial_info.model_save_path)[0], os.path.splitext(pipeline.trial_info.model_save_path)[1]))\n",
    "                        base_model.save_model(check_for_file_duplicates_short(os.path.splitext(pipeline.trial_info.model_save_path)[0], os.path.splitext(pipeline.trial_info.model_save_path)[1]))\n",
    "                    elif pipeline.modality.model_choice in ['SVM', 'KNN', 'RF']:\n",
    "                        joblib.dump(base_model, check_for_file_duplicates_short(os.path.splitext(pipeline.trial_info.model_save_path)[0], '.joblib'))\n",
    "                    elif pipeline.modality.model_choice == 'XGB':\n",
    "                        base_model.save_model(check_for_file_duplicates_short(os.path.splitext(pipeline.trial_info.model_save_path)[0], '.json'))\n",
    "                    elif pipeline.modality.model_choice == 'CAT':\n",
    "                        base_model.save_model(check_for_file_duplicates_short(os.path.splitext(pipeline.trial_info.model_save_path)[0], '.cbm'))\n",
    "                    print(f'Final Model {pipeline.modality.model_choice} trained and saved successfully. ({model_idx + 1} / {len(module_results.trained_models)})')\n",
    "\n",
    "        elif pipeline.modality.mode == 'eval':\n",
    "            \n",
    "            for check_target in ['../Hyperparameter tuning/Optuna', '../Model Evaluation']:\n",
    "                if pipeline.check_folder_structure(check_target):\n",
    "                    models_to_load = pipeline.finalize_trials(check_target)\n",
    "        \n",
    "            models_to_load_list = []\n",
    "            for sub_mode in ['eval']:  \n",
    "                pipeline.modality.mode = sub_mode\n",
    "                models_to_load = pipeline.load_models_by_type(models_to_load)\n",
    "                print(f'models_to_load: {models_to_load}')\n",
    "                models_to_load_df = pd.DataFrame(models_to_load)\n",
    "                # models_to_load_df = models_to_load_df.iloc[:, -4:] if sub_mode == 'eval' else models_to_load_df\n",
    "                models_to_load_list.append(models_to_load_df)\n",
    "\n",
    "            metric_summary = pd.concat(models_to_load_list, axis=1)\n",
    "            metric_summary = metric_summary.drop(columns='model')\n",
    "            print(f'metric_summary: {metric_summary}')\n",
    "            metric_summary.to_csv(pipeline.trial_info.summary_save_path, index=False)\n",
    "\n",
    "            # * \n",
    "            df = metric_summary\n",
    "            # heatmap_cols = ['Val Accuracy', 'Test Accuracy', 'Test F1', 'Test F2', 'Test AUC']\n",
    "            # for col in heatmap_cols:\n",
    "            #     df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "            # # Debug: Check data types\n",
    "            # print(\"Data types before heatmap:\")\n",
    "            # print(df[heatmap_cols].dtypes)\n",
    "\n",
    "            # # Get unique model classes\n",
    "            # model_classes = df['model class'].unique()\n",
    "\n",
    "            # # Get all unique feature combinations for consistent y-axis\n",
    "            # all_features = sorted(df['feature combination'].unique())\n",
    "\n",
    "            # # Create a figure with subplots (one per model class)\n",
    "            # fig, axes = plt.subplots(1, len(model_classes), figsize=(len(model_classes) * 5, max(8, len(all_features) * 0.4)),\n",
    "            #                         sharey=True, gridspec_kw={'wspace': 0.1})\n",
    "\n",
    "            # # Ensure axes is a list for single model case\n",
    "            # if len(model_classes) == 1:\n",
    "            #     axes = [axes]\n",
    "\n",
    "            # # Create heatmap for each model class\n",
    "            # for idx, model in enumerate(model_classes):\n",
    "            #     # Filter data for the current model\n",
    "            #     model_data = df[df['model class'] == model]\n",
    "                \n",
    "            #     # Create a DataFrame with all feature combinations, filling missing with NaN\n",
    "            #     heatmap_data = pd.DataFrame(index=all_features, columns=heatmap_cols)\n",
    "            #     for feature in all_features:\n",
    "            #         if feature in model_data['feature combination'].values:\n",
    "            #             row = model_data[model_data['feature combination'] == feature][heatmap_cols].iloc[0]\n",
    "            #             heatmap_data.loc[feature] = row\n",
    "            #         else:\n",
    "            #             heatmap_data.loc[feature] = [float('nan')] * len(heatmap_cols)\n",
    "                \n",
    "            #     # Convert heatmap_data to numeric to ensure float type\n",
    "            #     heatmap_data = heatmap_data.astype(float)\n",
    "                \n",
    "            #     # Debug: Check heatmap_data for non-numeric values\n",
    "            #     print(f\"\\nHeatmap data for {model}:\")\n",
    "            #     print(heatmap_data)\n",
    "                \n",
    "            #     # Plot heatmap\n",
    "            #     sns.heatmap(\n",
    "            #         heatmap_data,\n",
    "            #         annot=True,  # Show values in cells\n",
    "            #         cmap='YlGnBu',  # Color scheme\n",
    "            #         fmt='.3f',  # Format floats to 3 decimal places\n",
    "            #         cbar=(idx == len(model_classes) - 1),  # Colorbar only on last subplot\n",
    "            #         cbar_kws={'label': 'Score'} if idx == len(model_classes) - 1 else None,\n",
    "            #         ax=axes[idx],\n",
    "            #         yticklabels=all_features if idx == 0 else [],  # Y-labels only on first subplot\n",
    "            #     )\n",
    "            #     axes[idx].set_title(f'{model} Metrics')\n",
    "            #     axes[idx].set_xlabel('Metrics')\n",
    "            #     if idx == 0:\n",
    "            #         axes[idx].set_ylabel('Feature Combination')\n",
    "            #     else:\n",
    "            #         axes[idx].set_ylabel('')\n",
    "\n",
    "            # # Adjust layout\n",
    "            # plt.tight_layout()\n",
    "\n",
    "            # # Save the heatmap\n",
    "            # plt.savefig(f'../Model Evaluation/performance_heatmap_subplots_{pipeline.data.raw_dataset_name}.png')\n",
    "            # plt.close()\n",
    "\n",
    "            # ! only accounts for accuracy it seems like\n",
    "            # Create Table of Highest Val Accuracy per Model\n",
    "            highest_val_acc = df.loc[df.groupby('model class')[f'Val {pipeline.modality.metric}'].idxmax()]\n",
    "            # table_cols = ['dataset', 'model class', 'feature combination', 'Val Accuracy', 'Test Accuracy', 'Test F1', 'Test F2', 'Test AUC']\n",
    "            # highest_val_acc_table = highest_val_acc[table_cols]\n",
    "            highest_val_acc_table = highest_val_acc\n",
    "            highest_val_acc_table.to_csv(pipeline.trial_info.candidate_list_save_path, index=False)\n",
    "\n",
    "            # Print the table\n",
    "            print(\"\\nHighest Val Accuracy per Model:\")\n",
    "            print(highest_val_acc_table.to_string(index=False))\n",
    "            # * \n",
    "\n",
    "        elif pipeline.modality.mode == 'deploy':\n",
    "        \n",
    "            # model_candidate_summary_path = f'../Model Evaluation/highest_val_accuracy_per_model_{pipeline.data.raw_dataset_name}.csv'\n",
    "            # best_model_candidates_df = pd.read_csv(model_candidate_summary_path, header=0)\n",
    "            # print(best_model_candidates_df)\n",
    "\n",
    "            # models_to_load = []\n",
    "\n",
    "            # for best_model_candidate_idx in range(len(best_model_candidates_df)):\n",
    "            #     best_model_candidate_type = best_model_candidates_df.loc[best_model_candidate_idx, 'model class']\n",
    "            #     best_model_candidate_features = best_model_candidates_df.loc[best_model_candidate_idx, 'feature combination']\n",
    "            #     print(best_model_candidate_path)\n",
    "            #     best_model_candidate_path = f'../Model Evaluation/{pipeline.data.raw_dataset_name}/{best_model_candidate_type}/{best_model_candidate_features}/final*/{best_model_candidate_type}*'\n",
    "            #     model_and_info = {\n",
    "            #         'dataset': pipeline.data.raw_dataset_name,\n",
    "            #         'model class': best_model_candidate_type,\n",
    "            #         'feature combination': best_model_candidate_features,\n",
    "            #         'model': best_model_candidate_path\n",
    "            #     }\n",
    "            #     models_to_load.append(model_and_info)\n",
    "\n",
    "            # for dataset in ['tibial_slope_1', 'tibial_slope_2']:\n",
    "            #     pipeline.data.raw_dataset_name = dataset\n",
    "            #     models_to_load = pipeline.load_models_by_type\n",
    "\n",
    "            # metric_summary = pd.DataFrame(models_to_load)\n",
    "            # metric_summary = metric_summary.drop(columns='model')\n",
    "            # print(metric_summary)\n",
    "            # metric_summary.to_csv('../cross_test/cross_dataset_performance.csv', index=False)\n",
    "            pass\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"\\nTotal Execution Time: {execution_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
